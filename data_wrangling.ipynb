{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dependencies and determine working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Import NLP dictionaries\n",
    "import nltk\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get current directory\n",
    "dir = os.path.dirname(os.path.abspath('__file__'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load review data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load review data \n",
    "# Raw data in the format of {} {} {} seperated by lines\n",
    "\n",
    "# get file path (generalize for different OS) for reviews\n",
    "filename_review = os.path.join(dir, '01_raw_data','review.json')\n",
    "\n",
    "# create a list of reviews\n",
    "with open(filename_review, encoding=\"utf8\", mode='r') as file:\n",
    "    reviews = [json.loads(line) for line in file]\n",
    "\n",
    "# create a pandas data frame from review data \n",
    "reviews_df = pd.DataFrame(reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load business data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load business data \n",
    "\n",
    "# get file path (generalize for different OS) for reviews\n",
    "filename_business = os.path.join(dir, '01_raw_data','business.json')\n",
    "\n",
    "# create a list of reviews\n",
    "with open(filename_business, encoding=\"utf8\", mode='r') as file:\n",
    "    businesses = [json.loads(line) for line in file]\n",
    "\n",
    "# create a pandas data frame from review data \n",
    "businesses_df = pd.DataFrame(businesses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore review data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4736897, 9)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4736897 entries, 0 to 4736896\n",
      "Data columns (total 9 columns):\n",
      "business_id    object\n",
      "cool           int64\n",
      "date           object\n",
      "funny          int64\n",
      "review_id      object\n",
      "stars          int64\n",
      "text           object\n",
      "useful         int64\n",
      "user_id        object\n",
      "dtypes: int64(4), object(5)\n",
      "memory usage: 325.3+ MB\n",
      "None\n",
      "               cool         funny         stars        useful\n",
      "count  4.736897e+06  4.736897e+06  4.736897e+06  4.736897e+06\n",
      "mean   5.096600e-01  4.029171e-01  3.724048e+00  9.882921e-01\n",
      "std    1.960374e+00  1.721954e+00  1.421104e+00  2.600021e+00\n",
      "min    0.000000e+00  0.000000e+00  1.000000e+00  0.000000e+00\n",
      "25%    0.000000e+00  0.000000e+00  3.000000e+00  0.000000e+00\n",
      "50%    0.000000e+00  0.000000e+00  4.000000e+00  0.000000e+00\n",
      "75%    0.000000e+00  0.000000e+00  5.000000e+00  1.000000e+00\n",
      "max    5.130000e+02  6.310000e+02  5.000000e+00  1.125000e+03\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# review data exploration \n",
    "print(reviews_df.shape )\n",
    "print(reviews_df.info() )\n",
    "print(reviews_df.describe() )\n",
    "\n",
    "# check for null values\n",
    "print( reviews_df.isnull().sum().sum() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               business_id  cool        date  funny               review_id  \\\n",
      "0   uYHaNptLzDLoV_JZ_MuzUA     0  2016-07-12      0  VfBHSwC5Vz_pbFluy07i9Q   \n",
      "1   uYHaNptLzDLoV_JZ_MuzUA     0  2016-10-02      0  3zRpneRKDsOPq92tq7ybAA   \n",
      "2   uYHaNptLzDLoV_JZ_MuzUA     0  2015-09-17      0  ne5WhI1jUFOcRn-b-gAzHA   \n",
      "3   uYHaNptLzDLoV_JZ_MuzUA     0  2016-08-21      0  llmdwOgDReucVoWEry61Lw   \n",
      "4   uYHaNptLzDLoV_JZ_MuzUA     0  2013-11-20      0  DuffS87NaSMDmIfluvT83g   \n",
      "5   uYHaNptLzDLoV_JZ_MuzUA     0  2016-06-05      0  GvLmUkjUrOyFH8KFnmT1uw   \n",
      "6   uYHaNptLzDLoV_JZ_MuzUA     0  2015-02-21      0  lGEl24NGj2HVBJrodeXcjg   \n",
      "7   uYHaNptLzDLoV_JZ_MuzUA     0  2013-07-07      0  cUgvEy5wj7zYE68v1BzzVg   \n",
      "8   uYHaNptLzDLoV_JZ_MuzUA     2  2013-04-27      0  FSB_BnvysBgH3JYrbFNcgw   \n",
      "9   uYHaNptLzDLoV_JZ_MuzUA     0  2015-04-13      0  dhl3ZW9aAEX_T7_um5tfaQ   \n",
      "10  uYHaNptLzDLoV_JZ_MuzUA     1  2016-11-08      1  JQJvnM3p-3eML05eKcTgiw   \n",
      "11  uYHaNptLzDLoV_JZ_MuzUA     0  2015-07-27      0  6JF4WfHgwYrrdZ2VeYtnFw   \n",
      "12  uYHaNptLzDLoV_JZ_MuzUA     0  2014-05-07      0  fbVYETRuWDw8QnpimpGMpg   \n",
      "13  uYHaNptLzDLoV_JZ_MuzUA     0  2015-02-26      0  lobj38NgaokqVseN8_nn6g   \n",
      "14  uYHaNptLzDLoV_JZ_MuzUA     1  2015-08-21      0  ysfjtAWreLoy7um8WTb8xA   \n",
      "15  uYHaNptLzDLoV_JZ_MuzUA     0  2013-12-07      0  OF1ToqGAubsWGri5iad15w   \n",
      "16  jQsNFOzDpxPmOurSWCg1vQ     0  2017-06-03      0  ByRzJ8rF2KJWLr-cUNU6EA   \n",
      "17  jQsNFOzDpxPmOurSWCg1vQ     0  2015-03-26      0  i5UwUPlQFPLcE8p2gPFwBw   \n",
      "18  jQsNFOzDpxPmOurSWCg1vQ     1  2012-12-30      1  EyQyvTTg2jX4or9bB8PC9g   \n",
      "19  jQsNFOzDpxPmOurSWCg1vQ     1  2009-01-12      1  G-EFA005besj5uHsH0sQFA   \n",
      "20  jQsNFOzDpxPmOurSWCg1vQ     0  2015-07-11      0  6PcJSGUBSLjt4VLXos5C4A   \n",
      "21  jQsNFOzDpxPmOurSWCg1vQ     0  2015-05-27      0  PFJmyZD_lNBa_Y3kbX1VvA   \n",
      "22  jQsNFOzDpxPmOurSWCg1vQ     1  2015-02-28      1  _Qv1FQUToLrKMuG6pV4Gzw   \n",
      "23  jQsNFOzDpxPmOurSWCg1vQ     0  2010-04-05      0  s2mlqrFNaPEGtcnEu3EJ4Q   \n",
      "24  jQsNFOzDpxPmOurSWCg1vQ     0  2015-05-22      0  oiSzZRrbi3y01_wqU528ZQ   \n",
      "25  jQsNFOzDpxPmOurSWCg1vQ     0  2011-06-15      0  4BPjRE9VI0HhyZzyyYv0BQ   \n",
      "26  jQsNFOzDpxPmOurSWCg1vQ     0  2017-03-12      0  kznHtw1Qido_9GX6sDQPJw   \n",
      "27  jQsNFOzDpxPmOurSWCg1vQ     1  2016-12-19      0  HWRTVn3Lc-RwN6udv4WJzQ   \n",
      "28  jQsNFOzDpxPmOurSWCg1vQ     0  2011-08-10      0  GiEB_A-m9HuX521WQNbL8w   \n",
      "29  jQsNFOzDpxPmOurSWCg1vQ     0  2013-06-17      0  GKi4i6qocIgaYcwv1_0zzQ   \n",
      "30  jQsNFOzDpxPmOurSWCg1vQ     0  2015-11-03      0  OrhWg2MmCznwfKfjHKvuhA   \n",
      "31  jQsNFOzDpxPmOurSWCg1vQ     0  2017-07-08      0  QXWku_OB3FCj9VCZfUZwwg   \n",
      "32  jQsNFOzDpxPmOurSWCg1vQ     0  2015-09-22      0  5NtaW5EwXK595kP4Ynnisg   \n",
      "33  jQsNFOzDpxPmOurSWCg1vQ     0  2012-10-08      0  ai6O4UqqDqnjO7gfz6jBkA   \n",
      "34  jQsNFOzDpxPmOurSWCg1vQ     0  2015-12-28      0  ZrvsD7PSyPolII3gp4-uHw   \n",
      "35  jQsNFOzDpxPmOurSWCg1vQ     0  2009-11-18      0  p7OqbXTjwmIN_XYohB6TFw   \n",
      "36  jQsNFOzDpxPmOurSWCg1vQ     2  2012-07-29      2  ukpjwnetF5wGhGrSXmPRwA   \n",
      "37  jQsNFOzDpxPmOurSWCg1vQ     0  2016-06-19      0  mT6U5lujK_zIcIqux92seA   \n",
      "38  jQsNFOzDpxPmOurSWCg1vQ     0  2012-08-23      0  YxAxExTdWtdMhEb14RGFRg   \n",
      "39  jQsNFOzDpxPmOurSWCg1vQ     1  2009-06-25      1  ue6ts-gA9khywe76lEL1Kg   \n",
      "40  jQsNFOzDpxPmOurSWCg1vQ     0  2008-10-06      0  WsTYqsyNyUd7xpwFrgwI0g   \n",
      "41  jQsNFOzDpxPmOurSWCg1vQ     1  2015-03-17      1  g9yv-M3kvOQFPyJHCjUrdg   \n",
      "42  jQsNFOzDpxPmOurSWCg1vQ     0  2014-04-22      0  fk8OI26dAhQfot46T_SXWg   \n",
      "43  jQsNFOzDpxPmOurSWCg1vQ     0  2016-05-07      0  ld06EwR5YyutWxud9ude0Q   \n",
      "44  jQsNFOzDpxPmOurSWCg1vQ     1  2014-05-03      0  CxVx2FD73kw--RuzXL_RVA   \n",
      "45  jQsNFOzDpxPmOurSWCg1vQ     1  2014-05-29      1  jJaU6pbKkYgl15P-5zfg3A   \n",
      "46  jQsNFOzDpxPmOurSWCg1vQ     0  2009-12-10      0  7M2GCeIba1uTJMJbVO7TKw   \n",
      "47  jQsNFOzDpxPmOurSWCg1vQ     0  2014-10-01      0  pxs5biP-IzmjXZpoh-iVHg   \n",
      "48  jQsNFOzDpxPmOurSWCg1vQ     0  2015-07-13      0  DW0B2tlav4Z7T1DTzAL7kQ   \n",
      "49  jQsNFOzDpxPmOurSWCg1vQ     0  2016-02-14      0  nI2rhDM2CgNazMdhiODoRQ   \n",
      "\n",
      "    stars                                               text  useful  \\\n",
      "0       5  My girlfriend and I stayed here for 3 nights a...       0   \n",
      "1       3  If you need an inexpensive place to stay for a...       0   \n",
      "2       3  Mittlerweile gibt es in Edinburgh zwei Ableger...       0   \n",
      "3       4  Location is everything and this hotel has it! ...       0   \n",
      "4       5  gute lage im stadtzentrum. shoppingmeile und s...       0   \n",
      "5       5  Erstklassige Lage. Dazu ist alles geschrieben ...       0   \n",
      "6       4  Beautiful space, great location, staff rock. T...       0   \n",
      "7       4  This is a fairly new property I think. It is a...       0   \n",
      "8       4  First time at this group of hotels. Pretty new...       2   \n",
      "9       4  Location location location! \\n\\nMotel One is j...       2   \n",
      "10      4  A hotel that has all the basics that you'd nee...       1   \n",
      "11      3  Stayed here for two nights, costs was £109 per...       1   \n",
      "12      4  Well, i like the idea of Motel One. Always in ...       1   \n",
      "13      4  I really do love the Germans. This chain is sp...       1   \n",
      "14      5  Motel One sets the standard for budget hotels....       1   \n",
      "15      3  Had Continental style breakfast here a short d...       1   \n",
      "16      1  This place is horrible, we were so excited to ...       0   \n",
      "17      4  For being fairly \"fast\" food.. Pei Wei (pronou...       1   \n",
      "18      5  I decided to try it out, I'm celiac and theref...       2   \n",
      "19      3  I'm not saying Pei Wei is the best asian food ...       1   \n",
      "20      3  Sometimes the food is spot on and delicious an...       0   \n",
      "21      1  Decent customer service but the food was awful...       0   \n",
      "22      5  Super clean restaurant and friendly staff. FRE...       1   \n",
      "23      4  Found this the other night.  It is the PF Chan...       0   \n",
      "24      1  The staff here is great and they're nice,  won...       0   \n",
      "25      2  I had the garlic ginger broccoli chicken and i...       1   \n",
      "26      5  This review is based upon consistency of flavo...       0   \n",
      "27      5  I love this place i'd recommend it to anyone !...       1   \n",
      "28      4  1st! Place is not closed. There was an issue w...       1   \n",
      "29      2  Definitely not a fan. Coming from Orange Count...       0   \n",
      "30      3  Pretty good, not great. Definitely overpriced....       0   \n",
      "31      1  I wish I could give 1.5 stars. Nothing special...       0   \n",
      "32      2  Disappointed that on yelp their hours show the...       1   \n",
      "33      3  1st visit had the lo mein...delish!  \\n2nd vis...       0   \n",
      "34      5  As a vegetarian, it can difficult to find plac...       0   \n",
      "35      2  Typical big business chinese place. Slightly f...       0   \n",
      "36      4  I love Pei Wei since it's just a bit more affo...       1   \n",
      "37      4  Great fresh food and clean restaurant. Friendl...       1   \n",
      "38      3  This is pretty good. My wife and I usually spl...       0   \n",
      "39      4  Food is good and consistent and the service is...       2   \n",
      "40      4  The hubs and I dined at the Glendale location ...       0   \n",
      "41      3  Very clean and staff is always friendly. I usu...       2   \n",
      "42      1  If I could give no stars I would. My family pl...       0   \n",
      "43      5  I went to Surprise Pei Wei Restuarant tonight ...       0   \n",
      "44      4  I like Pei Wei overall and enjoy their varied ...       1   \n",
      "45      3  Everything was good except Thai chicken wraps....       0   \n",
      "46      1  I really don't understand how anyone can eat t...       1   \n",
      "47      2  Went in for lunch with a coworker today. The s...       0   \n",
      "48      5  The food is great and customer service is the ...       1   \n",
      "49      2  OH MY GOD, this place. I used to like Pei Wei ...       0   \n",
      "\n",
      "                   user_id  \n",
      "0   cjpdDjZyprfyDG3RlkVG3w  \n",
      "1   bjTcT8Ty4cJZhEOEo01FGA  \n",
      "2   AXgRULmWcME7J6Ix3I--ww  \n",
      "3   oU2SSOmsp_A8JYI7Z2JJ5w  \n",
      "4   0xtbPEna2Kei11vsU-U2Mw  \n",
      "5   rW8q706dz5-NnXDzMwVkiw  \n",
      "6   yx8vNXUL0D0HS8rUIC7AFA  \n",
      "7   zXnH6W74FAJQ7q7b-NuBsA  \n",
      "8   c5yp5hxwC1N98MjbV2LyWQ  \n",
      "9   xJisL5w4wOgiYLokGMT_IA  \n",
      "10  tgV6tsYQ66DZ3LQKvtC6cw  \n",
      "11  Q-3YCVywc03w56wYtGlKvg  \n",
      "12  Cx4UCow0zQgFQOp47RRRaA  \n",
      "13  eqWEgMH-DCP74i82BEAZzw  \n",
      "14  d0DGZRp6lHXGECJSc_nn-A  \n",
      "15  IpLZ7RevQrFPJWYc9Gxymg  \n",
      "16  kzyLOqiJvyw_FWFTw2rjiQ  \n",
      "17  WZXp9-V2dqRRJqhGgRqueA  \n",
      "18  XylT12exfdLiI_3uDLVIpw  \n",
      "19  Ji9PeffxjwqPLO7pEfSpKQ  \n",
      "20  TLIWzAJPrET0zX4_vgvLhg  \n",
      "21  JZEiTNWBwmv6MOOXYCAaMQ  \n",
      "22  E56sVQT5-OWfSejJrma8_w  \n",
      "23  4WYICo4emecA9r7sPYQkBw  \n",
      "24  P8mVj7AZwJTFFH5FXbbmUg  \n",
      "25  7Y4NEBQqWg7j-TvrQi6UZQ  \n",
      "26  vgZqQqe8cj6SBMH0EqDliw  \n",
      "27  O7G_c6wFXSygr82qs0GAcA  \n",
      "28  UG4EKu13JRwzRix6ESINdg  \n",
      "29  ZZG6yR27lIy3xwUYVgHO7w  \n",
      "30  1YorWW0Z-YDuYC5GplNabw  \n",
      "31  ujOPJEz_KxzAyZDnji-2Ng  \n",
      "32  6aEUn50d3Ts7MiGu6WdpKA  \n",
      "33  R6vb0FtmClhfwajs_AuusQ  \n",
      "34  CPuUagT2rfUJm6hRgxn3JQ  \n",
      "35  OYRBjBWy1uOm12N3cokS_Q  \n",
      "36  PKZLwAGgBtQCjJtGhyPETA  \n",
      "37  9bJ6j0zrV1XSiSnzQWM5Tw  \n",
      "38  8nCmV4RMwf4GpaN-A_2Tfw  \n",
      "39  tbAQMMVlhxvXhe6KifrZ-A  \n",
      "40  1s0Q1KwGpJIKvD-SRSpwjw  \n",
      "41  -0kiduTUToVYFqN_NEqMSw  \n",
      "42  KrQ_dWOBn2voaQLNv7hj8A  \n",
      "43  2L_1kyJDOkEaPDiBRohx9w  \n",
      "44  xlkjaJUu2fVojeaaVgQPOw  \n",
      "45  alTlRb9qMBX11pARX05Big  \n",
      "46  e--whH51bx5mDaMo3aJ-hg  \n",
      "47  Ns0hZ0xDOuVRMpHk0Q-5Yw  \n",
      "48  SM20gx7YH0GtI5JOXhfXdg  \n",
      "49  R-kL1bocHgP4GW7Mgd-ZXA  \n"
     ]
    }
   ],
   "source": [
    "# check output of first 50 \n",
    "print(reviews_df.head(50) )\n",
    "\n",
    "# outcome: some reviews look like accommodation and other non-restaurant business (e.g. first 15) \n",
    "# and some reviews are in a different language (e.g. index 4 and 5) and "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore business data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156639, 15)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 156639 entries, 0 to 156638\n",
      "Data columns (total 15 columns):\n",
      "address         156639 non-null object\n",
      "attributes      156639 non-null object\n",
      "business_id     156639 non-null object\n",
      "categories      156639 non-null object\n",
      "city            156639 non-null object\n",
      "hours           156639 non-null object\n",
      "is_open         156639 non-null int64\n",
      "latitude        156638 non-null float64\n",
      "longitude       156638 non-null float64\n",
      "name            156639 non-null object\n",
      "neighborhood    156639 non-null object\n",
      "postal_code     156639 non-null object\n",
      "review_count    156639 non-null int64\n",
      "stars           156639 non-null float64\n",
      "state           156639 non-null object\n",
      "dtypes: float64(3), int64(2), object(10)\n",
      "memory usage: 17.9+ MB\n",
      "None\n",
      "             is_open       latitude      longitude   review_count  \\\n",
      "count  156639.000000  156638.000000  156638.000000  156639.000000   \n",
      "mean        0.844375      38.585033     -92.856485      30.238159   \n",
      "std         0.362501       5.399871      26.557741      96.486631   \n",
      "min         0.000000     -36.086009    -142.466650       3.000000   \n",
      "25%         1.000000      33.627161    -112.138207       4.000000   \n",
      "50%         1.000000      36.142381     -89.523198       9.000000   \n",
      "75%         1.000000      43.596845     -79.668760      23.000000   \n",
      "max         1.000000      89.999314     115.086769    6979.000000   \n",
      "\n",
      "               stars  \n",
      "count  156639.000000  \n",
      "mean        3.647154  \n",
      "std         0.977640  \n",
      "min         1.000000  \n",
      "25%         3.000000  \n",
      "50%         3.500000  \n",
      "75%         4.500000  \n",
      "max         5.000000  \n",
      "2\n",
      "                               address  \\\n",
      "0                      691 Richmond Rd   \n",
      "1                       2824 Milton Rd   \n",
      "2                  337 Danforth Avenue   \n",
      "3  7702 E Doubletree Ranch Rd, Ste 300   \n",
      "4                       4719 N 20Th St   \n",
      "\n",
      "                                          attributes             business_id  \\\n",
      "0  {'RestaurantsPriceRange2': 2, 'BusinessParking...  YDf95gJZaq05wvo7hTQbbQ   \n",
      "1  {'GoodForMeal': {'dessert': False, 'latenight'...  mLwM-h2YhXl2NCgdS84_Bw   \n",
      "2  {'BusinessParking': {'garage': False, 'street'...  v2WhjAB3PIBA8J8VxG3wEg   \n",
      "3                                                 {}  CVtCbSB1zUcUWg-9TNGTuQ   \n",
      "4  {'RestaurantsTableService': False, 'GoodForMea...  duHFBe87uNSXImQmvBh87Q   \n",
      "\n",
      "                                          categories              city  \\\n",
      "0                       [Shopping, Shopping Centers]  Richmond Heights   \n",
      "1  [Food, Soul Food, Convenience Stores, Restaura...         Charlotte   \n",
      "2                               [Food, Coffee & Tea]           Toronto   \n",
      "3               [Professional Services, Matchmakers]        Scottsdale   \n",
      "4                          [Sandwiches, Restaurants]           Phoenix   \n",
      "\n",
      "                                               hours  is_open   latitude  \\\n",
      "0  {'Monday': '10:00-21:00', 'Tuesday': '10:00-21...        1  41.541716   \n",
      "1  {'Monday': '10:00-22:00', 'Tuesday': '10:00-22...        0  35.236870   \n",
      "2  {'Monday': '10:00-19:00', 'Tuesday': '10:00-19...        0  43.677126   \n",
      "3  {'Friday': '9:00-17:00', 'Tuesday': '9:00-17:0...        1  33.565082   \n",
      "4                                                 {}        0  33.505928   \n",
      "\n",
      "    longitude                                name neighborhood postal_code  \\\n",
      "0  -81.493116                Richmond Town Square                    44143   \n",
      "1  -80.741976  South Florida Style Chicken & Ribs     Eastland       28215   \n",
      "2  -79.353285                    The Tea Emporium    Riverdale     M4K 1N7   \n",
      "3 -111.916400                            TRUmatch                    85258   \n",
      "4 -112.038847                             Blimpie                    85016   \n",
      "\n",
      "   review_count  stars state  \n",
      "0            17    2.0    OH  \n",
      "1             4    4.5    NC  \n",
      "2             7    4.5    ON  \n",
      "3             3    3.0    AZ  \n",
      "4            10    4.5    AZ  \n"
     ]
    }
   ],
   "source": [
    "# business data exploration \n",
    "print(businesses_df.shape )\n",
    "print(businesses_df.info() )\n",
    "print(businesses_df.describe() )\n",
    "\n",
    "# check for null values\n",
    "print( businesses_df.isnull().sum().sum() )\n",
    "# outcome: 2 null values - one in lat, the other in long \n",
    "\n",
    "# check output\n",
    "print(businesses_df.head() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OH' 'NC' 'ON' 'AZ' 'PA' 'NV' 'EDH' 'QC' 'WI' 'IL' 'BW' 'HLD' 'SC' 'ESX'\n",
      " 'MLN' 'FIF' 'NYK' 'NI' 'ELN' 'WLN' '01' 'C' 'NY' 'SCB' 'AL' 'BY' 'RCC'\n",
      " 'ST' 'NTH' 'NLK' '75' 'PKN' 'HH' 'TAM' 'CA' 'KHL' 'VT' 'ABE' 'SL' 'DE'\n",
      " 'GLG' 'STG' 'ZET' 'XGL' 'WA' 'FLN' 'WHT' 'NE' 'FAL' '3' 'FL']\n",
      "count    156638.000000\n",
      "mean         38.585033\n",
      "std           5.399871\n",
      "min         -36.086009\n",
      "25%          33.627161\n",
      "50%          36.142381\n",
      "75%          43.596845\n",
      "max          89.999314\n",
      "Name: latitude, dtype: float64\n",
      "count    156638.000000\n",
      "mean        -92.856485\n",
      "std          26.557741\n",
      "min        -142.466650\n",
      "25%        -112.138207\n",
      "50%         -89.523198\n",
      "75%         -79.668760\n",
      "max         115.086769\n",
      "Name: longitude, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check if the businesses are located in the USA \n",
    "\n",
    "# Check if all the states are in the USA\n",
    "print( businesses_df['state'].unique() )\n",
    "\n",
    "# Check the lat long of the locations \n",
    "print(businesses_df['latitude'].describe() )\n",
    "print(businesses_df['longitude'].describe() )\n",
    "\n",
    "# Outcome: there appears to be non US states as well as lat long\n",
    "# bounding box for the US is (49.3457868 # north lat) (24.7433195 # south lat) (-124.7844079 # west long) (-66.9513812 # east long)\n",
    "# source: http://en.wikipedia.org/wiki/Extreme_points_of_the_United_States#Westernmost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean review data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert date to a datetime - note stars will be kept as an integer vs category\n",
    "reviews_df['date'] = pd.to_datetime(reviews_df['date'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean business data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51613, 15)\n"
     ]
    }
   ],
   "source": [
    "# Extract restaurants \n",
    "restaurants_df = businesses_df[ businesses_df['categories'].apply(lambda categories: any(pd.Series(categories).str.contains('Restaurants')) if len(categories)>0 else False)]\n",
    "print( restaurants_df.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Restrict restaurants to the USA using a bounding box \n",
    "restaurants_df = restaurants_df[ (restaurants_df['latitude'] >= 24.7433195) & (restaurants_df['latitude'] <= 49.3457868) & (restaurants_df['longitude'] >= -124.7844079) & (restaurants_df['longitude'] <= -66.9513812)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NC' 'AZ' 'PA' 'ON' 'WI' 'QC' 'IL' 'NV' 'OH' 'SC' 'NY' 'WA']\n",
      "count    48172.000000\n",
      "mean        39.444061\n",
      "std          4.434200\n",
      "min         33.137277\n",
      "25%         35.212550\n",
      "50%         40.464975\n",
      "75%         43.664307\n",
      "max         48.343443\n",
      "Name: latitude, dtype: float64\n",
      "count    48172.000000\n",
      "mean       -91.667579\n",
      "std         16.300928\n",
      "min       -119.551325\n",
      "25%       -111.975926\n",
      "50%        -80.979222\n",
      "75%        -79.419779\n",
      "max        -70.879166\n",
      "Name: longitude, dtype: float64\n",
      "(48172, 15)\n"
     ]
    }
   ],
   "source": [
    "# Check if the businesses are located in the USA \n",
    "\n",
    "# Check if all the states are in the USA\n",
    "print( restaurants_df['state'].unique() )\n",
    "\n",
    "# Check the lat long of the locations \n",
    "print(restaurants_df['latitude'].describe() )\n",
    "print(restaurants_df['longitude'].describe() )\n",
    "\n",
    "# Check to see if a significant proportion of the data set was dropped \n",
    "print( restaurants_df.shape )\n",
    "\n",
    "# outcome: states now limited to those in the USA and lat longs in the expected range of values - 51 613 to 48 172 observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop columns - address, city, hours, is_open, neighborhood, postal_code, state, latitude, longitude\n",
    "dropped_columns = ['address','city','hours', 'is_open','neighborhood','postal_code', 'state', 'latitude', 'longitude']\n",
    "for column in dropped_columns:\n",
    "    del restaurants_df[column]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge review data with restaurant's data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge both data frames\n",
    "joint_df = pd.merge(reviews_df, restaurants_df, on='business_id', suffixes=['_review', '_business'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore merged data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2876509, 14)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2876509 entries, 0 to 2876508\n",
      "Data columns (total 14 columns):\n",
      "business_id       object\n",
      "cool              int64\n",
      "date              datetime64[ns]\n",
      "funny             int64\n",
      "review_id         object\n",
      "stars_review      int64\n",
      "text              object\n",
      "useful            int64\n",
      "user_id           object\n",
      "attributes        object\n",
      "categories        object\n",
      "name              object\n",
      "review_count      int64\n",
      "stars_business    float64\n",
      "dtypes: datetime64[ns](1), float64(1), int64(5), object(7)\n",
      "memory usage: 329.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print( joint_df.shape )\n",
    "print( joint_df.info() )\n",
    "\n",
    "# outcome: no missing values\n",
    "# Inner join reduced the total number of reviews from 4 736 897 to the 2 927 731 from restaurants to the 2 876 509 from restaurants in the USA bounding box "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAD4CAYAAAApWAtMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAEPRJREFUeJzt3X2s3mV9x/H3RyoONQLKSeNatCQ2\nasVNoSssLMbJBgWN5Q81oJGGMJrFOt1YMuuWpT6EBJNlTDJlIaNaEicy5kK3IbUBdXELSFFjhWo4\nwwfa8FApwnxk6Hd/3Ffl9nifUzhX21+Pfb+SO/fv972u63dd507TT38P92mqCkmSejxj6AVIkhY+\nw0SS1M0wkSR1M0wkSd0ME0lSN8NEktTNMJEkdTNMJEndDBNJUrdFQy/gUDnhhBNq2bJlQy9DkhaU\nO++883tVNbW/fkdMmCxbtozt27cPvQxJWlCSfOep9PMylySpm2EiSepmmEiSuhkmkqRuhokkqZth\nIknqZphIkroZJpKkbkfMlxYPhGUb/mPoJfDty18/9BIk6Vd4ZiJJ6maYSJK6GSaSpG6GiSSpm2Ei\nSepmmEiSuhkmkqRuhokkqZthIknqtt8wSbIpyUNJvj5We36SbUnuae/Ht3qSXJlkOsnXkpwyNmZt\n639PkrVj9VOT7GhjrkyS+c4hSRrGUzkz+TiwekZtA3BLVS0Hbmn7AOcAy9trHXAVjIIB2AicBqwC\nNu4Lh9bnkrFxq+czhyRpOPsNk6r6T2DvjPIaYHPb3gycN1a/tkZuA45L8kLgbGBbVe2tqkeAbcDq\n1va8qrqtqgq4dsaxns4ckqSBzPeeyeKqur9tPwAsbttLgPvG+u1qtbnquybU5zPHr0iyLsn2JNv3\n7NnzFH80SdLT1X0Dvp1R1AFYywGfo6qurqqVVbVyamrqIKxMkgTzD5MH911aau8Ptfpu4MSxfktb\nba760gn1+cwhSRrIfMNkC7Dviay1wI1j9QvbE1enA4+2S1VbgbOSHN9uvJ8FbG1tjyU5vT3FdeGM\nYz2dOSRJA9nvf46V5JPAa4ETkuxi9FTW5cD1SS4GvgO8pXW/CTgXmAZ+BFwEUFV7k3wQuKP1+0BV\n7bup/w5GT4wdA3ymvXi6c0iShrPfMKmqC2ZpOnNC3wLWz3KcTcCmCfXtwMkT6g8/3TkkScPwG/CS\npG6GiSSpm2EiSepmmEiSuhkmkqRuhokkqZthIknqZphIkroZJpKkboaJJKmbYSJJ6maYSJK6GSaS\npG6GiSSpm2EiSepmmEiSuhkmkqRuhokkqZthIknqZphIkroZJpKkboaJJKmbYSJJ6maYSJK6GSaS\npG6GiSSpm2EiSepmmEiSuhkmkqRuhokkqVtXmCT5syR3Jfl6kk8m+Y0kJyW5Pcl0kk8lObr1fVbb\nn27ty8aO895W/2aSs8fqq1ttOsmGsfrEOSRJw5h3mCRZArwLWFlVJwNHAecDHwKuqKqXAI8AF7ch\nFwOPtPoVrR9JVrRxrwBWAx9NclSSo4CPAOcAK4ALWl/mmEOSNIDey1yLgGOSLAKeDdwPvA64obVv\nBs5r22vaPq39zCRp9euq6qdV9S1gGljVXtNVdW9VPQ5cB6xpY2abQ5I0gEXzHVhVu5P8DfBd4MfA\nZ4E7ge9X1ROt2y5gSdteAtzXxj6R5FHgBa1+29ihx8fcN6N+Whsz2xy/JMk6YB3Ai170ovn9oJrs\nfccOvQJ436NDr0BS03OZ63hGZxUnAb8JPIfRZarDRlVdXVUrq2rl1NTU0MuRpF9bPZe5/gD4VlXt\nqar/Az4NnAEc1y57ASwFdrft3cCJAK39WODh8fqMMbPVH55jDknSAHrC5LvA6Ume3e5jnAncDXwO\neFPrsxa4sW1vafu09lurqlr9/Pa010nAcuBLwB3A8vbk1tGMbtJvaWNmm0OSNIB5h0lV3c7oJviX\ngR3tWFcD7wEuTTLN6P7GNW3INcALWv1SYEM7zl3A9YyC6GZgfVX9rN0TeSewFdgJXN/6MscckqQB\nzPsGPEBVbQQ2zijfy+hJrJl9fwK8eZbjXAZcNqF+E3DThPrEOSRJw/Ab8JKkboaJJKmbYSJJ6maY\nSJK6GSaSpG6GiSSpm2EiSepmmEiSuhkmkqRuhokkqZthIknqZphIkroZJpKkboaJJKmbYSJJ6maY\nSJK6GSaSpG6GiSSpm2EiSepmmEiSuhkmkqRuhokkqZthIknqZphIkroZJpKkboaJJKmbYSJJ6maY\nSJK6GSaSpG6GiSSpW1eYJDkuyQ1JvpFkZ5LfTfL8JNuS3NPej299k+TKJNNJvpbklLHjrG3970my\ndqx+apIdbcyVSdLqE+eQJA2j98zkw8DNVfUy4LeBncAG4JaqWg7c0vYBzgGWt9c64CoYBQOwETgN\nWAVsHAuHq4BLxsatbvXZ5pAkDWDeYZLkWOA1wDUAVfV4VX0fWANsbt02A+e17TXAtTVyG3BckhcC\nZwPbqmpvVT0CbANWt7bnVdVtVVXAtTOONWkOSdIAes5MTgL2AB9L8pUk/5jkOcDiqrq/9XkAWNy2\nlwD3jY3f1Wpz1XdNqDPHHL8kybok25Ns37Nnz3x+RknSU9ATJouAU4CrqurVwA+ZcbmpnVFUxxz7\nNdccVXV1Va2sqpVTU1MHcxmSdETrCZNdwK6qur3t38AoXB5sl6ho7w+19t3AiWPjl7baXPWlE+rM\nMYckaQDzDpOqegC4L8lLW+lM4G5gC7Dviay1wI1tewtwYXuq63Tg0XapaitwVpLj2433s4Ctre2x\nJKe3p7gunHGsSXNIkgawqHP8nwCfSHI0cC9wEaOAuj7JxcB3gLe0vjcB5wLTwI9aX6pqb5IPAne0\nfh+oqr1t+x3Ax4FjgM+0F8Dls8whSRpAV5hU1VeBlROazpzQt4D1sxxnE7BpQn07cPKE+sOT5pAk\nDcNvwEuSuhkmkqRuhokkqZthIknqZphIkroZJpKkboaJJKmbYSJJ6maYSJK6GSaSpG6GiSSpm2Ei\nSepmmEiSuhkmkqRuhokkqZthIknqZphIkroZJpKkboaJJKmbYSJJ6maYSJK6GSaSpG6GiSSpm2Ei\nSepmmEiSuhkmkqRuhokkqZthIknqZphIkrp1h0mSo5J8Jcm/t/2TktyeZDrJp5Ic3erPavvTrX3Z\n2DHe2+rfTHL2WH11q00n2TBWnziHJGkYB+LM5N3AzrH9DwFXVNVLgEeAi1v9YuCRVr+i9SPJCuB8\n4BXAauCjLaCOAj4CnAOsAC5ofeeaQ5I0gEU9g5MsBV4PXAZcmiTA64C3ti6bgfcBVwFr2jbADcDf\nt/5rgOuq6qfAt5JMA6tav+mqurfNdR2wJsnOOeaQDrlXbn7l0Etgx9odQy9BR7jeM5O/A/4C+Hnb\nfwHw/ap6ou3vApa07SXAfQCt/dHW/xf1GWNmq881hyRpAPMOkyRvAB6qqjsP4HoOqCTrkmxPsn3P\nnj1DL0eSfm31nJmcAbwxybeB6xhdevowcFySfZfPlgK72/Zu4ESA1n4s8PB4fcaY2eoPzzHHL6mq\nq6tqZVWtnJqamv9PKkma07zDpKreW1VLq2oZoxvot1bV24DPAW9q3dYCN7btLW2f1n5rVVWrn9+e\n9joJWA58CbgDWN6e3Dq6zbGljZltDknSAA7G90zew+hm/DSj+xvXtPo1wAta/VJgA0BV3QVcD9wN\n3Aysr6qftXsi7wS2Mnpa7PrWd645JEkD6Hqaa5+q+jzw+bZ9L08+jTXe5yfAm2cZfxmjJ8Jm1m8C\nbppQnziHJGkYfgNektTNMJEkdTNMJEndDBNJUjfDRJLUzTCRJHUzTCRJ3QwTSVI3w0SS1M0wkSR1\nOyC/TkWSAHa+7OVDL4GXf2Pn/jvpgPPMRJLUzTCRJHUzTCRJ3QwTSVI3w0SS1M0wkSR1M0wkSd38\nnokkHQQf+eNbh14C6//hdYdsLs9MJEndDBNJUjfDRJLUzTCRJHUzTCRJ3QwTSVI3w0SS1M0wkSR1\nM0wkSd0ME0lSN8NEktRt3mGS5MQkn0tyd5K7kry71Z+fZFuSe9r78a2eJFcmmU7ytSSnjB1rbet/\nT5K1Y/VTk+xoY65MkrnmkCQNo+fM5Angz6tqBXA6sD7JCmADcEtVLQduafsA5wDL22sdcBWMggHY\nCJwGrAI2joXDVcAlY+NWt/psc0iSBjDvMKmq+6vqy237f4GdwBJgDbC5ddsMnNe21wDX1shtwHFJ\nXgicDWyrqr1V9QiwDVjd2p5XVbdVVQHXzjjWpDkkSQM4IPdMkiwDXg3cDiyuqvtb0wPA4ra9BLhv\nbNiuVpurvmtCnTnmkCQNoDtMkjwX+BfgT6vqsfG2dkZRvXPMZa45kqxLsj3J9j179hzMZUjSEa0r\nTJI8k1GQfKKqPt3KD7ZLVLT3h1p9N3Di2PClrTZXfemE+lxz/JKqurqqVlbVyqmpqfn9kJKk/ep5\nmivANcDOqvrbsaYtwL4nstYCN47VL2xPdZ0OPNouVW0FzkpyfLvxfhawtbU9luT0NteFM441aQ5J\n0gB6/tveM4C3AzuSfLXV/hK4HLg+ycXAd4C3tLabgHOBaeBHwEUAVbU3yQeBO1q/D1TV3rb9DuDj\nwDHAZ9qLOeaQJA1g3mFSVV8EMkvzmRP6F7B+lmNtAjZNqG8HTp5Qf3jSHJKkYfgNeElSN8NEktTN\nMJEkdTNMJEndDBNJUjfDRJLUzTCRJHUzTCRJ3QwTSVI3w0SS1M0wkSR1M0wkSd0ME0lSN8NEktTN\nMJEkdTNMJEndDBNJUjfDRJLUzTCRJHUzTCRJ3QwTSVI3w0SS1M0wkSR1M0wkSd0ME0lSN8NEktTN\nMJEkdTNMJEndDBNJUjfDRJLUbcGGSZLVSb6ZZDrJhqHXI0lHsgUZJkmOAj4CnAOsAC5IsmLYVUnS\nkWtBhgmwCpiuqnur6nHgOmDNwGuSpCNWqmroNTxtSd4ErK6qP2r7bwdOq6p3zui3DljXdl8KfPOQ\nLnSyE4DvDb2Iw4SfxYifw5P8LJ50uHwWL66qqf11WnQoVjKUqroauHrodYxLsr2qVg69jsOBn8WI\nn8OT/CyetNA+i4V6mWs3cOLY/tJWkyQNYKGGyR3A8iQnJTkaOB/YMvCaJOmItSAvc1XVE0neCWwF\njgI2VdVdAy/rqTqsLrsNzM9ixM/hSX4WT1pQn8WCvAEvSTq8LNTLXJKkw4hhIknqZphIkroZJhpE\nkmuHXsNQkqxK8jtte0WSS5OcO/S6pB4L8mmuhSjJ7zH6NTBfr6rPDr2eQynJzMe2A/x+kuMAquqN\nh35Vw0iykdHvlFuUZBtwGvA5YEOSV1fVZYMuUINJ8jJgCXB7Vf1grL66qm4ebmVPjU9zHSRJvlRV\nq9r2JcB64F+Bs4B/q6rLh1zfoZTky8DdwD8CxShMPsno+0FU1ReGW92hlWQH8CrgWcADwNKqeizJ\nMYz+EvmtQRd4GElyUVV9bOh1HApJ3sXo74idjP58vLuqbmxtX66qU4Zc31PhZa6D55lj2+uAP6yq\n9zMKk7cNs6TBrATuBP4KeLSqPg/8uKq+cCQFSfNEVf2sqn4E/E9VPQZQVT8Gfj7s0g477x96AYfQ\nJcCpVXUe8Frgr5O8u7VlsFU9DV7mOniekeR4RoGdqtoDUFU/TPLEsEs7tKrq58AVSf65vT/Ikftn\n7/Ekz25hcuq+YpJjOQLDJMnXZmsCFh/KtQzsGfsubVXVt5O8FrghyYsxTI54xzL613iASvLCqro/\nyXNZIH84DrSq2gW8OcnrgceGXs9AXlNVP4VfhOw+zwTWDrOkQS0GzgYemVEP8N+HfjmDeTDJq6rq\nqwBV9YMkbwA2Aa8cdmlPjfdMDrEkzwYWV9W3hl6LNLQk1wAfq6ovTmj7p6p66wDLOuSSLGV0CfSB\nCW1nVNV/DbCsp8UwkSR18wa8JKmbYSJJ6maYSJK6GSaSpG7/D61nSvqab5iqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x102eeada0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# bar char of review stars \n",
    "review_stars = joint_df['stars_review'].value_counts()\n",
    "review_stars.plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process review text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get stop words and lemmatizing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/chriskhoo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/chriskhoo/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Get stop words \n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stopWords = set(stopwords.words('english'))\n",
    "\n",
    "# Include puncutation into stop words \n",
    "stop_words_punc = stopWords.union(string.punctuation )\n",
    "\n",
    "# Get lemmertizer\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# import tokenizer\n",
    "from nltk.tokenize import wordpunct_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a function that cleans a single review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hey', 'test', 'sample', 'review', '...;', 'punctuation', 'upper', 'case', 'letter', 'walk', 'walking', 'walk', 'cat', 'cactus', 'lemmatizing']\n"
     ]
    }
   ],
   "source": [
    "# references: https://www.kaggle.com/c/word2vec-nlp-tutorial#part-1-for-beginners-bag-of-words \n",
    "# https://radimrehurek.com/data_science_python/\n",
    "# http://textminingonline.com/dive-into-nltk-part-iv-stemming-and-lemmatization\n",
    "# https://stackoverflow.com/questions/19130512/stopword-removal-with-nltk\n",
    "# https://stackoverflow.com/questions/46203023/how-can-i-make-my-python-nltk-pre-processing-code-more-efficient\n",
    "\n",
    "def pre_process_review( review_text ):\n",
    "    # Convert all text to lower case, tokenize into list of strings, remove punctuation and stop words, and lemmertize\n",
    "    return [lemmatizer.lemmatize(word) for word in wordpunct_tokenize(review_text.lower()) if not word in stop_words_punc]\n",
    "\n",
    "# Test pre_process_review function \n",
    "print( pre_process_review(\"Hey you! Test this sample review, with this: and this ...; and other punctuations and UPPER case letters! And walk, walking, walks, cats and cacti for lemmatizing.\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Apply pre-processing to all review text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [place, horrible, excited, try, since, got, gi...\n",
       "1     [fairly, fast, food, .., pei, wei, pronounced,...\n",
       "2     [decided, try, celiac, therefore, eat, gluten,...\n",
       "3     [saying, pei, wei, best, asian, food, ever, ta...\n",
       "4     [sometimes, food, spot, delicious, time, quite...\n",
       "5     [decent, customer, service, food, awful, cold,...\n",
       "6     [super, clean, restaurant, friendly, staff, fr...\n",
       "7     [found, night, pf, chang, fast, food, option, ...\n",
       "8     [staff, great, nice, wonderful, quick, people,...\n",
       "9     [garlic, ginger, broccoli, chicken, good, broc...\n",
       "10    [review, based, upon, consistency, flavor, gre...\n",
       "11    [love, place, recommend, anyone, always, order...\n",
       "12    [1st, place, closed, issue, legal, worker, fra...\n",
       "13    [definitely, fan, coming, orange, county, ca, ...\n",
       "14    [pretty, good, great, definitely, overpriced, ...\n",
       "15    [wish, could, give, 1, 5, star, nothing, speci...\n",
       "16    [disappointed, yelp, hour, show, open, 1030am,...\n",
       "17    [1st, visit, lo, mein, ..., delish, 2nd, visit...\n",
       "18    [vegetarian, difficult, find, place, good, opt...\n",
       "19    [typical, big, business, chinese, place, sligh...\n",
       "Name: processed_review, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply pre processing to review text and store result in a new column\n",
    "joint_df['processed_review'] = joint_df['text'].apply(lambda review_text: pre_process_review( review_text ))\n",
    "\n",
    "# Check output\n",
    "joint_df['processed_review'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               business_id  cool       date  funny               review_id  \\\n",
      "0   jQsNFOzDpxPmOurSWCg1vQ     0 2017-06-03      0  ByRzJ8rF2KJWLr-cUNU6EA   \n",
      "1   jQsNFOzDpxPmOurSWCg1vQ     0 2015-03-26      0  i5UwUPlQFPLcE8p2gPFwBw   \n",
      "2   jQsNFOzDpxPmOurSWCg1vQ     1 2012-12-30      1  EyQyvTTg2jX4or9bB8PC9g   \n",
      "3   jQsNFOzDpxPmOurSWCg1vQ     1 2009-01-12      1  G-EFA005besj5uHsH0sQFA   \n",
      "4   jQsNFOzDpxPmOurSWCg1vQ     0 2015-07-11      0  6PcJSGUBSLjt4VLXos5C4A   \n",
      "5   jQsNFOzDpxPmOurSWCg1vQ     0 2015-05-27      0  PFJmyZD_lNBa_Y3kbX1VvA   \n",
      "6   jQsNFOzDpxPmOurSWCg1vQ     1 2015-02-28      1  _Qv1FQUToLrKMuG6pV4Gzw   \n",
      "7   jQsNFOzDpxPmOurSWCg1vQ     0 2010-04-05      0  s2mlqrFNaPEGtcnEu3EJ4Q   \n",
      "8   jQsNFOzDpxPmOurSWCg1vQ     0 2015-05-22      0  oiSzZRrbi3y01_wqU528ZQ   \n",
      "9   jQsNFOzDpxPmOurSWCg1vQ     0 2011-06-15      0  4BPjRE9VI0HhyZzyyYv0BQ   \n",
      "10  jQsNFOzDpxPmOurSWCg1vQ     0 2017-03-12      0  kznHtw1Qido_9GX6sDQPJw   \n",
      "11  jQsNFOzDpxPmOurSWCg1vQ     1 2016-12-19      0  HWRTVn3Lc-RwN6udv4WJzQ   \n",
      "12  jQsNFOzDpxPmOurSWCg1vQ     0 2011-08-10      0  GiEB_A-m9HuX521WQNbL8w   \n",
      "13  jQsNFOzDpxPmOurSWCg1vQ     0 2013-06-17      0  GKi4i6qocIgaYcwv1_0zzQ   \n",
      "14  jQsNFOzDpxPmOurSWCg1vQ     0 2015-11-03      0  OrhWg2MmCznwfKfjHKvuhA   \n",
      "15  jQsNFOzDpxPmOurSWCg1vQ     0 2017-07-08      0  QXWku_OB3FCj9VCZfUZwwg   \n",
      "16  jQsNFOzDpxPmOurSWCg1vQ     0 2015-09-22      0  5NtaW5EwXK595kP4Ynnisg   \n",
      "17  jQsNFOzDpxPmOurSWCg1vQ     0 2012-10-08      0  ai6O4UqqDqnjO7gfz6jBkA   \n",
      "18  jQsNFOzDpxPmOurSWCg1vQ     0 2015-12-28      0  ZrvsD7PSyPolII3gp4-uHw   \n",
      "19  jQsNFOzDpxPmOurSWCg1vQ     0 2009-11-18      0  p7OqbXTjwmIN_XYohB6TFw   \n",
      "\n",
      "    stars_review                                               text  useful  \\\n",
      "0              1  This place is horrible, we were so excited to ...       0   \n",
      "1              4  For being fairly \"fast\" food.. Pei Wei (pronou...       1   \n",
      "2              5  I decided to try it out, I'm celiac and theref...       2   \n",
      "3              3  I'm not saying Pei Wei is the best asian food ...       1   \n",
      "4              3  Sometimes the food is spot on and delicious an...       0   \n",
      "5              1  Decent customer service but the food was awful...       0   \n",
      "6              5  Super clean restaurant and friendly staff. FRE...       1   \n",
      "7              4  Found this the other night.  It is the PF Chan...       0   \n",
      "8              1  The staff here is great and they're nice,  won...       0   \n",
      "9              2  I had the garlic ginger broccoli chicken and i...       1   \n",
      "10             5  This review is based upon consistency of flavo...       0   \n",
      "11             5  I love this place i'd recommend it to anyone !...       1   \n",
      "12             4  1st! Place is not closed. There was an issue w...       1   \n",
      "13             2  Definitely not a fan. Coming from Orange Count...       0   \n",
      "14             3  Pretty good, not great. Definitely overpriced....       0   \n",
      "15             1  I wish I could give 1.5 stars. Nothing special...       0   \n",
      "16             2  Disappointed that on yelp their hours show the...       1   \n",
      "17             3  1st visit had the lo mein...delish!  \\n2nd vis...       0   \n",
      "18             5  As a vegetarian, it can difficult to find plac...       0   \n",
      "19             2  Typical big business chinese place. Slightly f...       0   \n",
      "\n",
      "                   user_id                                         attributes  \\\n",
      "0   kzyLOqiJvyw_FWFTw2rjiQ  {'RestaurantsTableService': False, 'GoodForMea...   \n",
      "1   WZXp9-V2dqRRJqhGgRqueA  {'RestaurantsTableService': False, 'GoodForMea...   \n",
      "2   XylT12exfdLiI_3uDLVIpw  {'RestaurantsTableService': False, 'GoodForMea...   \n",
      "3   Ji9PeffxjwqPLO7pEfSpKQ  {'RestaurantsTableService': False, 'GoodForMea...   \n",
      "4   TLIWzAJPrET0zX4_vgvLhg  {'RestaurantsTableService': False, 'GoodForMea...   \n",
      "5   JZEiTNWBwmv6MOOXYCAaMQ  {'RestaurantsTableService': False, 'GoodForMea...   \n",
      "6   E56sVQT5-OWfSejJrma8_w  {'RestaurantsTableService': False, 'GoodForMea...   \n",
      "7   4WYICo4emecA9r7sPYQkBw  {'RestaurantsTableService': False, 'GoodForMea...   \n",
      "8   P8mVj7AZwJTFFH5FXbbmUg  {'RestaurantsTableService': False, 'GoodForMea...   \n",
      "9   7Y4NEBQqWg7j-TvrQi6UZQ  {'RestaurantsTableService': False, 'GoodForMea...   \n",
      "10  vgZqQqe8cj6SBMH0EqDliw  {'RestaurantsTableService': False, 'GoodForMea...   \n",
      "11  O7G_c6wFXSygr82qs0GAcA  {'RestaurantsTableService': False, 'GoodForMea...   \n",
      "12  UG4EKu13JRwzRix6ESINdg  {'RestaurantsTableService': False, 'GoodForMea...   \n",
      "13  ZZG6yR27lIy3xwUYVgHO7w  {'RestaurantsTableService': False, 'GoodForMea...   \n",
      "14  1YorWW0Z-YDuYC5GplNabw  {'RestaurantsTableService': False, 'GoodForMea...   \n",
      "15  ujOPJEz_KxzAyZDnji-2Ng  {'RestaurantsTableService': False, 'GoodForMea...   \n",
      "16  6aEUn50d3Ts7MiGu6WdpKA  {'RestaurantsTableService': False, 'GoodForMea...   \n",
      "17  R6vb0FtmClhfwajs_AuusQ  {'RestaurantsTableService': False, 'GoodForMea...   \n",
      "18  CPuUagT2rfUJm6hRgxn3JQ  {'RestaurantsTableService': False, 'GoodForMea...   \n",
      "19  OYRBjBWy1uOm12N3cokS_Q  {'RestaurantsTableService': False, 'GoodForMea...   \n",
      "\n",
      "                                           categories     name  review_count  \\\n",
      "0   [Fast Food, Gluten-Free, Asian Fusion, Diners,...  Pei Wei            92   \n",
      "1   [Fast Food, Gluten-Free, Asian Fusion, Diners,...  Pei Wei            92   \n",
      "2   [Fast Food, Gluten-Free, Asian Fusion, Diners,...  Pei Wei            92   \n",
      "3   [Fast Food, Gluten-Free, Asian Fusion, Diners,...  Pei Wei            92   \n",
      "4   [Fast Food, Gluten-Free, Asian Fusion, Diners,...  Pei Wei            92   \n",
      "5   [Fast Food, Gluten-Free, Asian Fusion, Diners,...  Pei Wei            92   \n",
      "6   [Fast Food, Gluten-Free, Asian Fusion, Diners,...  Pei Wei            92   \n",
      "7   [Fast Food, Gluten-Free, Asian Fusion, Diners,...  Pei Wei            92   \n",
      "8   [Fast Food, Gluten-Free, Asian Fusion, Diners,...  Pei Wei            92   \n",
      "9   [Fast Food, Gluten-Free, Asian Fusion, Diners,...  Pei Wei            92   \n",
      "10  [Fast Food, Gluten-Free, Asian Fusion, Diners,...  Pei Wei            92   \n",
      "11  [Fast Food, Gluten-Free, Asian Fusion, Diners,...  Pei Wei            92   \n",
      "12  [Fast Food, Gluten-Free, Asian Fusion, Diners,...  Pei Wei            92   \n",
      "13  [Fast Food, Gluten-Free, Asian Fusion, Diners,...  Pei Wei            92   \n",
      "14  [Fast Food, Gluten-Free, Asian Fusion, Diners,...  Pei Wei            92   \n",
      "15  [Fast Food, Gluten-Free, Asian Fusion, Diners,...  Pei Wei            92   \n",
      "16  [Fast Food, Gluten-Free, Asian Fusion, Diners,...  Pei Wei            92   \n",
      "17  [Fast Food, Gluten-Free, Asian Fusion, Diners,...  Pei Wei            92   \n",
      "18  [Fast Food, Gluten-Free, Asian Fusion, Diners,...  Pei Wei            92   \n",
      "19  [Fast Food, Gluten-Free, Asian Fusion, Diners,...  Pei Wei            92   \n",
      "\n",
      "    stars_business                                   processed_review  \n",
      "0              3.5  [place, horrible, excited, try, since, got, gi...  \n",
      "1              3.5  [fairly, fast, food, .., pei, wei, pronounced,...  \n",
      "2              3.5  [decided, try, celiac, therefore, eat, gluten,...  \n",
      "3              3.5  [saying, pei, wei, best, asian, food, ever, ta...  \n",
      "4              3.5  [sometimes, food, spot, delicious, time, quite...  \n",
      "5              3.5  [decent, customer, service, food, awful, cold,...  \n",
      "6              3.5  [super, clean, restaurant, friendly, staff, fr...  \n",
      "7              3.5  [found, night, pf, chang, fast, food, option, ...  \n",
      "8              3.5  [staff, great, nice, wonderful, quick, people,...  \n",
      "9              3.5  [garlic, ginger, broccoli, chicken, good, broc...  \n",
      "10             3.5  [review, based, upon, consistency, flavor, gre...  \n",
      "11             3.5  [love, place, recommend, anyone, always, order...  \n",
      "12             3.5  [1st, place, closed, issue, legal, worker, fra...  \n",
      "13             3.5  [definitely, fan, coming, orange, county, ca, ...  \n",
      "14             3.5  [pretty, good, great, definitely, overpriced, ...  \n",
      "15             3.5  [wish, could, give, 1, 5, star, nothing, speci...  \n",
      "16             3.5  [disappointed, yelp, hour, show, open, 1030am,...  \n",
      "17             3.5  [1st, visit, lo, mein, ..., delish, 2nd, visit...  \n",
      "18             3.5  [vegetarian, difficult, find, place, good, opt...  \n",
      "19             3.5  [typical, big, business, chinese, place, sligh...  \n"
     ]
    }
   ],
   "source": [
    "print(joint_df.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save output of data wrangling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save merged data of reviews and restaurants in the USA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save df into a tsv (approx 5 mins)\n",
    "filename_out = os.path.join(dir, '02_processed_data','restaurant_reviews.csv')\n",
    "joint_df.to_csv(filename_out, index=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load output of CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (3,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Load df from a tsv (approx 5 mins)\n",
    "file_path = os.path.join(dir, '02_processed_data','restaurant_reviews.csv')\n",
    "joint_df2 = pd.read_csv(file_path, index_col = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2876509, 15)\n",
      "(2876509, 15)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2876509 entries, 0 to 2876508\n",
      "Data columns (total 15 columns):\n",
      "business_id         object\n",
      "cool                int64\n",
      "date                datetime64[ns]\n",
      "funny               int64\n",
      "review_id           object\n",
      "stars_review        int64\n",
      "text                object\n",
      "useful              int64\n",
      "user_id             object\n",
      "attributes          object\n",
      "categories          object\n",
      "name                object\n",
      "review_count        int64\n",
      "stars_business      float64\n",
      "processed_review    object\n",
      "dtypes: datetime64[ns](1), float64(1), int64(5), object(8)\n",
      "memory usage: 431.1+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2876509 entries, 0 to 2876509\n",
      "Data columns (total 15 columns):\n",
      "business_id         object\n",
      "cool                int64\n",
      "date                datetime64[ns]\n",
      "funny               int64\n",
      "review_id           object\n",
      "stars_review        object\n",
      "text                object\n",
      "useful              int64\n",
      "user_id             object\n",
      "attributes          object\n",
      "categories          object\n",
      "name                object\n",
      "review_count        int64\n",
      "stars_business      float64\n",
      "processed_review    object\n",
      "dtypes: datetime64[ns](1), float64(1), int64(4), object(9)\n",
      "memory usage: 351.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# run checks to see the frames are the same \n",
    "assert( joint_df.shape == joint_df2.shape)\n",
    "print( joint_df.shape )\n",
    "print( joint_df2.shape )\n",
    "\n",
    "print( joint_df.info() )\n",
    "print( joint_df2.info() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .str accessor with string values, which use np.object_ dtype in pandas",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-83e6499aeee9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# strip out errorenous review\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'^\\d{4}-\\d{2}-\\d{2}$'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoint_df2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Invert the mask: mask_inverse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   3608\u001b[0m         if (name in self._internal_names_set or name in self._metadata or\n\u001b[1;32m   3609\u001b[0m                 name in self._accessors):\n\u001b[0;32m-> 3610\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3611\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3612\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/accessor.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, instance, owner)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;31m# this ensures that Series.str.<method> is well defined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccessor_cls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct_accessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__set__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36m_make_accessor\u001b[0;34m(cls, data)\u001b[0m\n\u001b[1;32m   1904\u001b[0m             \u001b[0;31m# (instead of test for object dtype), but that isn't practical for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1905\u001b[0m             \u001b[0;31m# performance reasons until we have a str dtype (GH 9343)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1906\u001b[0;31m             raise AttributeError(\"Can only use .str accessor with string \"\n\u001b[0m\u001b[1;32m   1907\u001b[0m                                  \u001b[0;34m\"values, which use np.object_ dtype in \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1908\u001b[0m                                  \"pandas\")\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can only use .str accessor with string values, which use np.object_ dtype in pandas"
     ]
    }
   ],
   "source": [
    "# strip out errorenous review \n",
    "pattern = '^\\d{4}-\\d{2}-\\d{2}$'\n",
    "mask = joint_df2['date'].str.contains(pattern)\n",
    "\n",
    "# Invert the mask: mask_inverse\n",
    "mask_inverse = ~mask\n",
    "\n",
    "# Subset countries using mask_inverse: invalid_countries\n",
    "invalid_entries = joint_df2['date'].loc[mask_inverse]\n",
    "\n",
    "print(np.where(mask_inverse)[0][0])\n",
    "joint_df2.drop(joint_df2.index[np.where(mask_inverse)[0][0]], inplace=True)\n",
    "print(joint_df2.iloc[np.where(mask_inverse)[0][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "joint_df2['date'] = pd.to_datetime(joint_df['date'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_name in ['cool', 'funny', 'useful', 'review_count']:\n",
    "    joint_df2[col_name] = joint_df2[col_name].fillna(0).astype(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize pre-processed text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n"
     ]
    }
   ],
   "source": [
    "# Initialize scikit-learn's bag of words tool -  \"CountVectorizer\"\n",
    "# Source: http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "n_features = 3000\n",
    "vectorizer = CountVectorizer(analyzer = 'word',\n",
    "                             max_features = n_features,\n",
    "                             max_df=0.95, \n",
    "                             min_df=2).fit(\"\".join(line) for line in joint_df['processed_review'])\n",
    "print (len(vectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vectorize text and convert the result to an Numpy array\n",
    "vectorized_text = vectorizer.transform(\"\".join(line) for line in joint_df['processed_review'])\n",
    "vectorized_text_array = vectorized_text.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore word vector properties and most common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparse matrix shape: (2876509, 3000)\n",
      "number of non-zeros: 232154\n",
      "sparsity: 0.00%\n",
      "wow                     3837\n",
      "loveplace               3752\n",
      "good                    3028\n",
      "back                    2805\n",
      "amazing                 2591\n",
      "delicious               2400\n",
      "yum                     2240\n",
      "ok                      2207\n",
      "well                    2060\n",
      "omg                     1875\n",
      "love                    1755\n",
      "lol                     1741\n",
      "really                  1722\n",
      "disappointed            1479\n",
      "yummy                   1438\n",
      "go                      1391\n",
      "food                    1385\n",
      "awesome                 1265\n",
      "http                    1189\n",
      "definitelyback          1187\n",
      "wait                    1158\n",
      "10                      1102\n",
      "know                    1081\n",
      "say                     1074\n",
      "seriously               1068\n",
      "yes                     1052\n",
      "meh                      998\n",
      "greatfood                980\n",
      "placeamazing             947\n",
      "12                       916\n",
      "                        ... \n",
      "presentation              14\n",
      "lovefoodservice           14\n",
      "anywhereelse              14\n",
      "gethype                   14\n",
      "garlicbread               14\n",
      "6star                     14\n",
      "loving                    14\n",
      "pleaseeat                 14\n",
      "thai                      14\n",
      "greatdessert              14\n",
      "bestbuffet                14\n",
      "greatfry                  14\n",
      "smriti                    14\n",
      "shut                      14\n",
      "silly                     14\n",
      "simply                    14\n",
      "simplyawesome             14\n",
      "lookforwardgoingback      14\n",
      "slowly                    14\n",
      "smallplace                14\n",
      "greatplacegreatfood       14\n",
      "spicytunaroll             14\n",
      "soooogoood                14\n",
      "greatpizzawing            14\n",
      "greatmargarita            14\n",
      "soooyummy                 14\n",
      "greatlunchspecial         14\n",
      "sp                        14\n",
      "spent                     14\n",
      "amen                      14\n",
      "Length: 3000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get list of words in the vocabulary\n",
    "vocab = vectorizer.get_feature_names()\n",
    "\n",
    "# Sum up the counts of each vocabulary word\n",
    "dist = np.sum(vectorized_text_array, axis=0)\n",
    "\n",
    "# Explore vector metrics\n",
    "print ('sparse matrix shape:', vectorized_text.shape)\n",
    "print ('number of non-zeros:', vectorized_text.nnz)\n",
    "print ('sparsity: %.2f%%' % (100.0 * vectorized_text.nnz / (vectorized_text.shape[0] * vectorized_text.shape[1])))\n",
    "\n",
    "# Print most used words in reverse order\n",
    "print( pd.Series( dict(list(zip(vocab, dist))) ).sort_values( ascending = False) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define vectorizer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n"
     ]
    }
   ],
   "source": [
    "# Initialize scikit-learn's bag of words tool -  \"CountVectorizer\"\n",
    "# Source: http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "n_features = 3000\n",
    "vectorizer = CountVectorizer(analyzer = pre_process_review,\n",
    "                             max_features = n_features,\n",
    "                             max_df=0.95, \n",
    "                             min_df=2).fit(joint_df['text'])\n",
    "print (len(vectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize text 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vectorize text and convert the result to an Numpy array\n",
    "vectorized_text = vectorizer.transform(joint_df['text'])\n",
    "vectorized_text_array = vectorized_text.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore word vector properties and most common words 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparse matrix shape: (2876509, 3000)\n",
      "number of non-zeros: 123705583\n",
      "sparsity: 1.43%\n",
      "food           2293171\n",
      "good           1892858\n",
      "place          1889152\n",
      "great          1344620\n",
      "service        1180824\n",
      "time           1178872\n",
      "like           1131077\n",
      "one            1004655\n",
      "get             938087\n",
      "back            863566\n",
      "go              857214\n",
      "really          827370\n",
      "restaurant      826086\n",
      "would           821958\n",
      "...             751625\n",
      "ordered         700710\n",
      "order           698338\n",
      "u               669442\n",
      "also            658247\n",
      "chicken         643743\n",
      "menu            595335\n",
      "got             580615\n",
      "nice            557659\n",
      "best            555557\n",
      "come            543735\n",
      "well            541939\n",
      "came            533220\n",
      "try             531427\n",
      "delicious       526938\n",
      "table           519562\n",
      "                ...   \n",
      "thicker           5416\n",
      "train             5416\n",
      "horchata          5414\n",
      "brûlée            5410\n",
      "pissed            5406\n",
      "hesitant          5403\n",
      "kim               5396\n",
      "diego             5396\n",
      "elevator          5395\n",
      "shout             5394\n",
      "bleu              5394\n",
      "mocha             5393\n",
      "information       5384\n",
      "celery            5381\n",
      "language          5379\n",
      "strike            5379\n",
      "flan              5373\n",
      "jazz              5372\n",
      "ensure            5367\n",
      "creamed           5367\n",
      "pocket            5361\n",
      "manage            5356\n",
      "toilet            5356\n",
      "rub               5352\n",
      "oreo              5349\n",
      "department        5344\n",
      "trick             5336\n",
      "vip               5335\n",
      "liver             5334\n",
      "cube              5332\n",
      "Length: 3000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get list of words in the vocabulary\n",
    "vocab = vectorizer.get_feature_names()\n",
    "\n",
    "# Sum up the counts of each vocabulary word\n",
    "dist = np.sum(vectorized_text_array, axis=0)\n",
    "\n",
    "# Explore vector metrics\n",
    "print ('sparse matrix shape:', vectorized_text.shape)\n",
    "print ('number of non-zeros:', vectorized_text.nnz)\n",
    "print ('sparsity: %.2f%%' % (100.0 * vectorized_text.nnz / (vectorized_text.shape[0] * vectorized_text.shape[1])))\n",
    "\n",
    "# Print most used words in reverse order\n",
    "print( pd.Series( dict(list(zip(vocab, dist))) ).sort_values( ascending = False) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Explore the vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24 37 59 ..., 69 34 28]\n"
     ]
    }
   ],
   "source": [
    "# Sum up the word counts of each review\n",
    "review_words = np.sum(vectorized_text_array, axis=1)\n",
    "print(review_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean : 52.0579914751\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAD8CAYAAACYebj1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqTEUJEnN/wPe1Da6IWsWsAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x28eae7908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print( 'Mean :', np.mean(review_words) )\n",
    "review_word_count = pd.Series(review_words)\n",
    "review_word_count.plot(kind='hist', bins=25, normed=True, cumulative=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save vectorized text array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save vectorized text into a npy\n",
    "# https://stackoverflow.com/questions/28439701/how-to-save-and-load-numpy-array-data-properly\n",
    "filename_out = os.path.join(dir, '02_processed_data','vectorized_reviews.npy')\n",
    "np.save(filename_out, vectorized_text_array)    # .npy extension is added if not given\n",
    "\n",
    "# note to load use vectorized_text_array = np.load(filename_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
