{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dependencies and determine working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/chriskhoo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "from collections import Counter, defaultdict\n",
    "import numpy as np\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Import topic model \n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "\n",
    "# Get stop words \n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Import NLP vectorizers\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import word2vec\n",
    "\n",
    "# Import models \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "import keras\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get current directory\n",
    "dir = os.path.dirname(os.path.abspath('__file__'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pre-processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2876509 entries, 0 to 2876508\n",
      "Data columns (total 2 columns):\n",
      "stars_review        int64\n",
      "processed_review    object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 43.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# Load df from a csv - all text to lower case, tokenize into list of strings, remove punctuation and lemmatize\n",
    "preprocessed_path = os.path.join(dir, '02_processed_data','review_text_stars.csv')\n",
    "preprocessed_df = pd.read_csv(preprocessed_path, index_col = False)\n",
    "preprocessed_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create training and test sets using a fixed seed for reproducibility \n",
    "X_train, X_test, y_train, y_test = train_test_split(preprocessed_df.processed_review, preprocessed_df.stars_review, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create mini dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20136\n"
     ]
    }
   ],
   "source": [
    "# Create a mini data set for feature and model selection (for manageable training times)\n",
    "__, X_mini, ___, y_mini = train_test_split(X_train, y_train, test_size = 0.01, random_state = 42)\n",
    "print(len(X_mini))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word 2 Vec using mini dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create corpus of sentences from mini\n",
    "sentence_corpus_mini = []\n",
    "for review in X_mini:\n",
    "    words = review.split(\"', '\")\n",
    "    words[0] = words[0][2:]\n",
    "    words[-1] = words[-1][:-2]\n",
    "    sentence_corpus_mini.append(' '.join(words))\n",
    "\n",
    "# Create tokenized corpus\n",
    "wpt = nltk.WordPunctTokenizer()\n",
    "tokenized_corpus = [wpt.tokenize(document) for document in sentence_corpus_mini]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# Create word 2 vec model \n",
    "feature_size = 100\n",
    "w2v_model = word2vec.Word2Vec(tokenized_corpus, size=feature_size, window=5, min_count=10, workers=4)\n",
    "w2v_dictionary = dict(zip(w2v_model.wv.index2word, w2v_model.wv.syn0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define functions to create a feature array\n",
    "def average_word_vectors(words, model, vocabulary, num_features):   \n",
    "    feature_vector = np.zeros((num_features,),dtype=\"float64\")\n",
    "    nwords = 0.   \n",
    "    for word in words:\n",
    "        if word in vocabulary: \n",
    "            nwords = nwords + 1.\n",
    "            feature_vector = np.add(feature_vector, model[word])\n",
    "    if nwords:\n",
    "        feature_vector = np.divide(feature_vector, nwords)\n",
    "    return feature_vector\n",
    "    \n",
    "def averaged_word_vectorizer(corpus, model, num_features):\n",
    "    vocabulary = set(model.wv.index2word)\n",
    "    features = [average_word_vectors(tokenized_sentence, model, vocabulary, num_features)\n",
    "                    for tokenized_sentence in corpus]\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20136, 100)\n"
     ]
    }
   ],
   "source": [
    "w2v_feature_array = averaged_word_vectorizer(corpus=tokenized_corpus, model=w2v_model,\n",
    "                                             num_features=feature_size)\n",
    "w2v_mini = pd.DataFrame(w2v_feature_array)\n",
    "print(w2v_mini.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14095\n"
     ]
    }
   ],
   "source": [
    "w2v_mini_train, w2v_mini_test, y_mini_train, y_mini_test = train_test_split(w2v_mini, y_mini, test_size = 0.3, random_state = 42)\n",
    "print(len(w2v_mini_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection using mini dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the mini dataset, a variety of models will be trained on a variety of feature sets to identify promising candidates. The promising combinations will then be tuned in the following section and trained on the full training data set. \n",
    "\n",
    "It should be noted that to assess model performance, the classification accuracy will be the primary metric. \n",
    "A Confusion matrix will be created using the best performing parameters from the cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define model tuning\n",
    "def cross_validation_tuning(classifier, param_grid, X_trn, y_trn):\n",
    "    classifier_cv = GridSearchCV(classifier, param_grid, n_jobs=4, cv=3)\n",
    "    classifier_cv.fit(X_trn, y_trn)\n",
    "    # Print the optimal parameters and best score\n",
    "    print(\"Tuned Classifier Parameters: {}\".format(classifier_cv.best_params_))\n",
    "    print(\"Tuned Classifier Accuracy: {:.3f}\".format(classifier_cv.best_score_))\n",
    "    # Predict the labels\n",
    "    pred = classifier_cv.predict(X_trn)\n",
    "    # Compute accuracy\n",
    "    score = metrics.accuracy_score(y_trn, pred)\n",
    "    # Calculate and print the confusion matrix\n",
    "    cm = metrics.confusion_matrix(y_trn, pred, labels=[1,2,3,4,5])\n",
    "    print('For the confusion matrix, rows correspond to actual ratings and the columns correspond to predicted ratings.')\n",
    "    print(cm)\n",
    "    return classifier_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.541135573581\n",
      "For the confusion matrix, rows correspond to actual ratings and the columns correspond to predicted ratings.\n",
      "[[ 443   46   41   82   65]\n",
      " [ 190   68  118  164   77]\n",
      " [ 101   50  194  412  126]\n",
      " [  47   19   79  830  691]\n",
      " [  46    7   19  392 1734]]\n"
     ]
    }
   ],
   "source": [
    "logreg_model_1 = LogisticRegression(C= 1, penalty= 'l1')\n",
    "logreg_model_1.fit(w2v_mini_train, y_mini_train)\n",
    "w2v_logreg_pred = logreg_model_1.predict(w2v_mini_test)\n",
    "w2v_logreg_score = metrics.accuracy_score(y_mini_test, w2v_logreg_pred)\n",
    "w2v_logreg_cm = metrics.confusion_matrix(y_mini_test, w2v_logreg_pred, labels=[1,2,3,4,5])\n",
    "print(w2v_logreg_score)\n",
    "print('For the confusion matrix, rows correspond to actual ratings and the columns correspond to predicted ratings.')\n",
    "print(w2v_logreg_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.429233570601\n",
      "For the confusion matrix, rows correspond to actual ratings and the columns correspond to predicted ratings.\n",
      "[[404 140  82  38  13]\n",
      " [178 175 171  86   7]\n",
      " [ 87 197 283 296  20]\n",
      " [ 71 175 299 951 170]\n",
      " [102 179 179 958 780]]\n"
     ]
    }
   ],
   "source": [
    "sgd_model_1 = SGDClassifier(random_state= 42, n_jobs=4, max_iter=4, l1_ratio= 0.3, penalty ='elasticnet')\n",
    "sgd_model_1.fit(w2v_mini_train, y_mini_train)\n",
    "w2v_sgd_pred = sgd_model_1.predict(w2v_mini_test)\n",
    "w2v_sgd_score = metrics.accuracy_score(y_mini_test, w2v_sgd_pred)\n",
    "w2v_sgd_cm = metrics.confusion_matrix(y_mini_test, w2v_sgd_pred, labels=[1,2,3,4,5])\n",
    "print(w2v_sgd_score)\n",
    "print('For the confusion matrix, rows correspond to actual ratings and the columns correspond to predicted ratings.')\n",
    "print(w2v_sgd_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Classifier Parameters: {'C': 100, 'penalty': 'l1'}\n",
      "Tuned Classifier Accuracy: 0.552\n",
      "0.540804502566\n",
      "For the confusion matrix, rows correspond to actual ratings and the columns correspond to predicted ratings.\n",
      "[[ 436   56   44   71   70]\n",
      " [ 190   83  112  157   75]\n",
      " [  90   62  205  402  124]\n",
      " [  50   21   87  814  694]\n",
      " [  44    8   21  396 1729]]\n"
     ]
    }
   ],
   "source": [
    "logreg_param_grid = {'C': [0.0001, 1, 100], 'penalty': ['l1', 'l2']}\n",
    "logreg_model_1 = LogisticRegression()\n",
    "logreg_w2v_cv = GridSearchCV(logreg_model_1, logreg_param_grid, cv=3)\n",
    "logreg_w2v_cv.fit(w2v_mini_train, y_mini_train)\n",
    "print(\"Tuned Classifier Parameters: {}\".format(logreg_w2v_cv.best_params_))\n",
    "print(\"Tuned Classifier Accuracy: {:.3f}\".format(logreg_w2v_cv.best_score_))\n",
    "logreg_w2v_pred = logreg_w2v_cv.predict(w2v_mini_test)\n",
    "logreg_w2v_score = metrics.accuracy_score(y_mini_test, logreg_w2v_pred)\n",
    "logreg_w2v_cm = metrics.confusion_matrix(y_mini_test, logreg_w2v_pred, labels=[1,2,3,4,5])\n",
    "print(logreg_w2v_score)\n",
    "print('For the confusion matrix, rows correspond to actual ratings and the columns correspond to predicted ratings.')\n",
    "print(logreg_w2v_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Classifier Parameters: {'l1_ratio': 0.1, 'penalty': 'l1'}\n",
      "Tuned Classifier Accuracy: 0.457\n",
      "0.429564641616\n",
      "For the confusion matrix, rows correspond to actual ratings and the columns correspond to predicted ratings.\n",
      "[[322 211  87  45  12]\n",
      " [124 253 130 106   4]\n",
      " [ 45 256 224 341  17]\n",
      " [ 33 224 269 973 167]\n",
      " [ 42 189 188 956 823]]\n"
     ]
    }
   ],
   "source": [
    "sgd_param_grid = {\"penalty\": ['l1', 'l2', 'elasticnet'],\n",
    "                  \"l1_ratio\": [0.1, 0.3, 0.5] }\n",
    "sgd_model_1 = SGDClassifier(random_state= 42, max_iter=4)\n",
    "sgd_w2v_cv = GridSearchCV(sgd_model_1, sgd_param_grid, cv=3)\n",
    "sgd_w2v_cv.fit(w2v_mini_train, y_mini_train)\n",
    "print(\"Tuned Classifier Parameters: {}\".format(sgd_w2v_cv.best_params_))\n",
    "print(\"Tuned Classifier Accuracy: {:.3f}\".format(sgd_w2v_cv.best_score_))\n",
    "sgd_w2v_pred = sgd_w2v_cv.predict(w2v_mini_test)\n",
    "sgd_w2v_score = metrics.accuracy_score(y_mini_test, sgd_w2v_pred)\n",
    "sgd_w2v_cm = metrics.confusion_matrix(y_mini_test, sgd_w2v_pred, labels=[1,2,3,4,5])\n",
    "print(sgd_w2v_score)\n",
    "print('For the confusion matrix, rows correspond to actual ratings and the columns correspond to predicted ratings.')\n",
    "print(sgd_w2v_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
