{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dependencies and determine working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get current directory\n",
    "dir = os.path.dirname(os.path.abspath('__file__'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load review dataÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load review data \n",
    "# Raw data in the format of {} {} {} seperated by lines\n",
    "\n",
    "# get file path (generalize for different OS) for reviews\n",
    "filename_review = os.path.join(dir, '01_raw_data','review.json')\n",
    "\n",
    "# create a list of reviews\n",
    "with open(filename_review, encoding=\"utf8\", mode='r') as file:\n",
    "    reviews = [json.loads(line) for line in file]\n",
    "\n",
    "# create a pandas data frame from review data \n",
    "reviews_df = pd.DataFrame(reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load business data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load business data \n",
    "\n",
    "# get file path (generalize for different OS) for reviews\n",
    "filename_business = os.path.join(dir, '01_raw_data','business.json')\n",
    "\n",
    "# create a list of reviews\n",
    "with open(filename_business, encoding=\"utf8\", mode='r') as file:\n",
    "    businesses = [json.loads(line) for line in file]\n",
    "\n",
    "# create a pandas data frame from review data \n",
    "businesses_df = pd.DataFrame(businesses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge and pre-process data frames for inferential statistics\n",
    "Keep all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert date to a datetime - note stars will be kept as an integer vs category\n",
    "reviews_df['date'] = pd.to_datetime(reviews_df['date'], format='%Y-%m-%d')\n",
    "\n",
    "# Extract restaurants \n",
    "restaurants_df = businesses_df[ businesses_df['categories'].apply(lambda categories: any(pd.Series(categories).str.contains('Restaurants')) if len(categories)>0 else False)]\n",
    "\n",
    "# Restrict restaurants to the USA using a bounding box \n",
    "restaurants_df = restaurants_df[ (restaurants_df['latitude'] >= 24.7433195) & (restaurants_df['latitude'] <= 49.3457868) & (restaurants_df['longitude'] >= -124.7844079) & (restaurants_df['longitude'] <= -66.9513812)]\n",
    "\n",
    "# Merge both data frames\n",
    "joint_df = pd.merge(reviews_df, restaurants_df, on='business_id', suffixes=['_review', '_business'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2876509 entries, 0 to 2876508\n",
      "Data columns (total 23 columns):\n",
      "business_id       object\n",
      "cool              int64\n",
      "date              datetime64[ns]\n",
      "funny             int64\n",
      "review_id         object\n",
      "stars_review      int64\n",
      "text              object\n",
      "useful            int64\n",
      "user_id           object\n",
      "address           object\n",
      "attributes        object\n",
      "categories        object\n",
      "city              object\n",
      "hours             object\n",
      "is_open           int64\n",
      "latitude          float64\n",
      "longitude         float64\n",
      "name              object\n",
      "neighborhood      object\n",
      "postal_code       object\n",
      "review_count      int64\n",
      "stars_business    float64\n",
      "state             object\n",
      "dtypes: datetime64[ns](1), float64(3), int64(6), object(13)\n",
      "memory usage: 526.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(joint_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate decision to drop columns other than review text and review stars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    cool     funny  stars_review    useful   is_open  \\\n",
      "cool            1.000000  0.846138      0.042902  0.854624 -0.015011   \n",
      "funny           0.846138  1.000000     -0.041543  0.823759 -0.020031   \n",
      "stars_review    0.042902 -0.041543      1.000000 -0.040162  0.051385   \n",
      "useful          0.854624  0.823759     -0.040162  1.000000 -0.028944   \n",
      "is_open        -0.015011 -0.020031      0.051385 -0.028944  1.000000   \n",
      "latitude       -0.029170 -0.037964     -0.031977 -0.026753  0.011822   \n",
      "longitude      -0.047311 -0.051008     -0.033299 -0.035423  0.015738   \n",
      "review_count    0.022783  0.022769      0.066223  0.007781  0.084150   \n",
      "stars_business  0.043261 -0.000225      0.413689  0.012131  0.115686   \n",
      "\n",
      "                latitude  longitude  review_count  stars_business  \n",
      "cool           -0.029170  -0.047311      0.022783        0.043261  \n",
      "funny          -0.037964  -0.051008      0.022769       -0.000225  \n",
      "stars_review   -0.031977  -0.033299      0.066223        0.413689  \n",
      "useful         -0.026753  -0.035423      0.007781        0.012131  \n",
      "is_open         0.011822   0.015738      0.084150        0.115686  \n",
      "latitude        1.000000   0.810437     -0.159074       -0.073632  \n",
      "longitude       0.810437   1.000000     -0.291484       -0.078719  \n",
      "review_count   -0.159074  -0.291484      1.000000        0.157608  \n",
      "stars_business -0.073632  -0.078719      0.157608        1.000000  \n"
     ]
    }
   ],
   "source": [
    "correlation_matrix = joint_df.corr(method='pearson')\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be noted that there are high correlations between 'cool', 'funny' and 'useful' reviews. This might be helpful for a future analysis of what makes a good review.\n",
    "\n",
    "However, the target of our current analysis, 'stars_review', does not have notable correlations to anything other than the 'stars_business'. This makes sense since 'stars_business' is the average of 'stars_review' for a restaurant and there are a large number of restaurants with a low number of reviews (see data story telling), however this isn't very helpful. \n",
    "\n",
    "Therefore, we can conclude that for our analysis of 'stars_review', we can drop the columns: 'cool', 'funny', 'useful', 'is_open', 'latitude', 'longitude', 'review_count', 'stars_business' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop numeric columns with low correlations\n",
    "dropped_columns = ['cool', 'funny', 'useful', 'is_open', 'latitude', 'longitude', 'review_count', 'stars_business']\n",
    "for column in dropped_columns:\n",
    "    del joint_df[column]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review non-numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state\n",
      "AZ    837240\n",
      "IL     22193\n",
      "NC    180619\n",
      "NV    949830\n",
      "NY        73\n",
      "OH    154764\n",
      "ON    414444\n",
      "PA    143304\n",
      "QC     98967\n",
      "SC      5981\n",
      "WA        39\n",
      "WI     69055\n",
      "Name: stars_review, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEKCAYAAAAW8vJGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nswwnBjMzy3BiMDOzjP8P3CurrEy9+EsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x107a92cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check if states are related to the star rating\n",
    "print(joint_df.groupby('state')['stars_review'].count())\n",
    "sns.boxplot(x='state', y='stars_review', data=joint_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of stars awarded by reviews are consistent with the exception of WA and SC. We see that WA has a very low number of reviews do not expect it to impact the analysis significantly. \n",
    "\n",
    "SC has a greater proportion of low star ratings but not a very high number of reviews. We suspect this will not significantly impact the analysis either.\n",
    "\n",
    "Since there is little correlation between 'stars_review', 'latitude' and 'longitude' as well as 'state', we will infer that location associated columns will not help us to determine the 'stars_review'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop columns associated with location\n",
    "dropped_columns = ['address', 'city', 'neighborhood', 'postal_code', 'state']\n",
    "for column in dropped_columns:\n",
    "    del joint_df[column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2876509 entries, 0 to 2876508\n",
      "Data columns (total 10 columns):\n",
      "business_id     object\n",
      "date            datetime64[ns]\n",
      "review_id       object\n",
      "stars_review    int64\n",
      "text            object\n",
      "user_id         object\n",
      "attributes      object\n",
      "categories      object\n",
      "hours           object\n",
      "name            object\n",
      "dtypes: datetime64[ns](1), int64(1), object(8)\n",
      "memory usage: 321.4+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(joint_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The point of a review is to rate a business, to assign the rating based on the business ID or name would reinforce the bias, therefore we will remove 'name', 'business_id'. Since 'review_id' is an idex, we'll remove that too. \n",
    "\n",
    "The remaining columns: 'user_id', 'attributes', 'categories', 'hours'\n",
    "- 'user_id' : in the previous analysis we noted that majority of reviews have no previews reviews \n",
    "- 'attributes', 'categories', 'hours': are descriptors of the business and not the review "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop columns associated with location\n",
    "dropped_columns = ['name', 'business_id', 'review_id', 'user_id', 'attributes', 'categories', 'hours']\n",
    "for column in dropped_columns:\n",
    "    del joint_df[column]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify that review text contain words that may be statistically significant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the exploratory data analysis section, it was observed that particular words such as 'bad' and 'best' might be good indicators of the star rating of the review. The hypothesis that frequency of occurrence for the two words are statistically significant will be tested. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pre-processed data (Uni-gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Load pre-processed data\n",
    "file_path = os.path.join(dir, '02_processed_data','restaurant_reviews.csv')\n",
    "pre_processed_joint_df = pd.read_csv(file_path, index_col = False, parse_dates= ['date'])\n",
    "\n",
    "# Initialize scikit-learn's bag of words tool -  \"CountVectorizer\"\n",
    "# Source: http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "vectorizer = CountVectorizer(analyzer = 'word',\n",
    "                             max_features= 5000,\n",
    "                             max_df=0.95, \n",
    "                             min_df=0.001)\n",
    "\n",
    "vectorized_uni_text = vectorizer.fit_transform( pre_processed_joint_df['processed_review'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get indices of 'bad' and 'best'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get index positions of the words 'bad' and 'best'\n",
    "vocab = vectorizer.vocabulary_\n",
    "index_of_bad = vocab['bad']\n",
    "index_of_best = vocab['best']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataframe for analysis\n",
    "- with reviews as observations, \n",
    "- the number of stars awarded by the review, \n",
    "- the number of times the words 'bad' and 'best' appeared in the review text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "555557\n"
     ]
    }
   ],
   "source": [
    "# Convert sparse matrix to dataframe\n",
    "dense_df = pd.DataFrame(vectorized_uni_text.toarray())\n",
    "\n",
    "# Extract bad and best columns\n",
    "bad_df = dense_df.iloc[:, index_of_bad]\n",
    "best_df = dense_df.iloc[:, index_of_best]\n",
    "\n",
    "# Verify that the best column has the same total as found in the data storytelling analysis - 555557\n",
    "print(sum(best_df))\n",
    "\n",
    "# Add the stars_review column to each of the data frames\n",
    "bad_best_df = pd.concat([pre_processed_joint_df['stars_review'], bad_df, best_df], axis=1)\n",
    "bad_best_df.columns = ['stars', 'bad', 'best']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permutation tests for data coming from identical distributions\n",
    "Since reviews are assumed to be independent events, the Central Limit Theorem (CLT) would be applicable to the rate of appearence of a frequently used word such as 'bad' or 'best'. In addition, the difference in frequency of occurences is expected to be normally distributed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define reusable functions (note: code adapted from Data Camp)\n",
    "def permutation_sample(data1, data2):\n",
    "    \"\"\"Generate a permutation sample from two data sets.\"\"\"\n",
    "\n",
    "    # Concatenate the data sets: data\n",
    "    data = np.concatenate((data1, data2))\n",
    "\n",
    "    # Permute the concatenated array: permuted_data\n",
    "    permuted_data = np.random.permutation(data)\n",
    "\n",
    "    # Split the permuted array into two: perm_sample_1, perm_sample_2\n",
    "    perm_sample_1 = permuted_data[:len(data1)]\n",
    "    perm_sample_2 = permuted_data[len(data1):]\n",
    "\n",
    "    return perm_sample_1, perm_sample_2\n",
    "\n",
    "def draw_perm_reps(data_1, data_2, func, size=1):\n",
    "    \"\"\"Generate multiple permutation replicates.\"\"\"\n",
    "\n",
    "    # Initialize array of replicates: perm_replicates\n",
    "    perm_replicates = np.empty(size)\n",
    "\n",
    "    for i in range(size):\n",
    "        # Generate permutation sample\n",
    "        perm_sample_1, perm_sample_2 = permutation_sample(data_1, data_2)\n",
    "\n",
    "        # Compute the test statistic\n",
    "        perm_replicates[i] = func(perm_sample_1, perm_sample_2)\n",
    "        \n",
    "#         # Output a value to inform the user of progress\n",
    "#         if i%500 == 0: print('Processing permutation :', i) \n",
    "\n",
    "    return perm_replicates\n",
    "\n",
    "def diff_of_means(data_1, data_2):\n",
    "    \"\"\"Difference in means of two arrays.\"\"\"\n",
    "\n",
    "    # The difference of means of data_1, data_2: diff\n",
    "    diff = np.mean(data_1) - np.mean(data_2)\n",
    "\n",
    "    return diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis test to see if the distribution of the word 'bad' is significantly different for 1 star reviews\n",
    "- Null hypothesis: The frequency of appearance of the word 'bad' is identical for 1 star rated reviews and the other reviews\n",
    "- Test statistic: Frequency (rate) of 'bad' appearing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create data sets \n",
    "bad_1star = bad_best_df[bad_best_df['stars'] == 1]['bad']\n",
    "bad_2345 = bad_best_df[bad_best_df['stars'] != 1]['bad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value = 0.0\n"
     ]
    }
   ],
   "source": [
    "# Compute empirical difference of frequency of appearance \n",
    "empirical_diff_means = diff_of_means(bad_1star, bad_2345)\n",
    "\n",
    "# Draw 10,000 permutation replicates: perm_replicates\n",
    "perm_replicates = draw_perm_reps(bad_1star, bad_2345,\n",
    "                               diff_of_means, size=10000)\n",
    "\n",
    "# Compute p-value: p\n",
    "p = np.sum(perm_replicates >= empirical_diff_means) / len(perm_replicates)\n",
    "\n",
    "# Print the result\n",
    "print('p-value =', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The empirical mean is:  0.131362022291\n",
      "The theoretical mean is:  -1.71939774808e-07\n",
      "The theoretical standard deviation is:  0.000653329613357\n"
     ]
    }
   ],
   "source": [
    "# Check empirical and hypothetical frequences \n",
    "print('The empirical mean is: ', empirical_diff_means)\n",
    "print('The theoretical mean is: ', np.mean(perm_replicates))\n",
    "print('The theoretical standard deviation is: ', np.std(perm_replicates))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value for the frequency of the word 'bad' occurring in the text of a 1 star review is statistically significant. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis test to see if the distribution of the word 'bad' is significantly different for 5 star reviews\n",
    "- Null hypothesis: The frequency of appearance of the word 'bad' is identical for 5 star rated reviews and the other reviews\n",
    "- Test statistic: Frequency (rate) of 'bad' appearing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create data sets \n",
    "bad_5star = bad_best_df[bad_best_df['stars'] == 5]['bad']\n",
    "bad_1234 = bad_best_df[bad_best_df['stars'] != 5]['bad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value = 0.0\n"
     ]
    }
   ],
   "source": [
    "# Compute empirical difference of frequency of appearance \n",
    "empirical_diff_means = diff_of_means(bad_5star, bad_1234)\n",
    "\n",
    "# Draw 10,000 permutation replicates: perm_replicates\n",
    "perm_replicates = draw_perm_reps(bad_5star, bad_1234,\n",
    "                               diff_of_means, size=10000)\n",
    "\n",
    "# Compute p-value: p\n",
    "p = np.sum(perm_replicates <= empirical_diff_means) / len(perm_replicates)\n",
    "\n",
    "# Print the result\n",
    "print('p-value =', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The empirical mean is:  -0.0941255822317\n",
      "The theoretical mean is:  4.69866328094e-06\n",
      "The theoretical standard deviation is:  0.000427959434541\n"
     ]
    }
   ],
   "source": [
    "# Check empirical and hypothetical frequences \n",
    "print('The empirical mean is: ', empirical_diff_means)\n",
    "print('The theoretical mean is: ', np.mean(perm_replicates))\n",
    "print('The theoretical standard deviation is: ', np.std(perm_replicates))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value for the frequency of the word 'bad' occurring in the text of a 5 star review is statistically significant. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis test to see if the distribution of the word 'best' is significantly different for 1 star reviews\n",
    "- Null hypothesis: The frequency of appearance of the word 'best' is identical for 1 star rated reviews and the other reviews\n",
    "- Test statistic: Frequency (rate) of 'best' appearing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create data sets \n",
    "best_1star = bad_best_df[bad_best_df['stars'] == 1]['best']\n",
    "best_2345 = bad_best_df[bad_best_df['stars'] != 1]['best']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value = 0.0\n"
     ]
    }
   ],
   "source": [
    "# Compute empirical difference of frequency of appearance \n",
    "empirical_diff_means = diff_of_means(best_1star, best_2345)\n",
    "\n",
    "# Draw 10,000 permutation replicates: perm_replicates\n",
    "perm_replicates = draw_perm_reps(best_1star, best_2345,\n",
    "                               diff_of_means, size=10000)\n",
    "\n",
    "# Compute p-value: p\n",
    "p = np.sum(perm_replicates <= empirical_diff_means) / len(perm_replicates)\n",
    "\n",
    "# Print the result\n",
    "print('p-value =', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The empirical mean is:  -0.137868742356\n",
      "The theoretical mean is:  3.62393846388e-06\n",
      "The theoretical standard deviation is:  0.000893537376816\n"
     ]
    }
   ],
   "source": [
    "# Check empirical and hypothetical frequences \n",
    "print('The empirical mean is: ', empirical_diff_means)\n",
    "print('The theoretical mean is: ', np.mean(perm_replicates))\n",
    "print('The theoretical standard deviation is: ', np.std(perm_replicates))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value for the frequency of the word 'best' occurring in the text of a 1 star review is statistically significant. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis test to see if the distribution of the word 'best' is significantly different for 5 star reviews\n",
    "- Null hypothesis: The frequency of appearance of the word 'best' is identical for 5 star rated reviews and the other reviews\n",
    "- Test statistic: Frequency (rate) of 'best' appearing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create data sets \n",
    "best_5star = bad_best_df[bad_best_df['stars'] == 5]['best']\n",
    "best_1234 = bad_best_df[bad_best_df['stars'] != 5]['best']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value = 0.0\n"
     ]
    }
   ],
   "source": [
    "# Compute empirical difference of frequency of appearance \n",
    "empirical_diff_means = diff_of_means(best_5star, best_1234)\n",
    "\n",
    "# Draw 10,000 permutation replicates: perm_replicates\n",
    "perm_replicates = draw_perm_reps(best_5star, best_1234,\n",
    "                               diff_of_means, size=10000)\n",
    "\n",
    "# Compute p-value: p\n",
    "p = np.sum(perm_replicates >= empirical_diff_means) / len(perm_replicates)\n",
    "\n",
    "# Print the result\n",
    "print('p-value =', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The empirical mean is:  0.152706439507\n",
      "The theoretical mean is:  1.91561885134e-06\n",
      "The theoretical standard deviation is:  0.000579717133499\n"
     ]
    }
   ],
   "source": [
    "# Check empirical and hypothetical frequences \n",
    "print('The empirical mean is: ', empirical_diff_means)\n",
    "print('The theoretical mean is: ', np.mean(perm_replicates))\n",
    "print('The theoretical standard deviation is: ', np.std(perm_replicates))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value for the frequency of the word 'best' occurring in the text of a 5 star review is statistically significant. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create data sets \n",
    "bad_1star = bad_best_df[bad_best_df['stars'] == 1]['bad']\n",
    "bad_5star = bad_best_df[bad_best_df['stars'] == 5]['bad']\n",
    "bad_all = bad_best_df['bad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of appearance:  0.212374838894\n",
      "Confidence interval for frequency of appearance:  -0.591059426563  to  0.782210575404\n",
      "Statistical significance:  0.630582852476\n"
     ]
    }
   ],
   "source": [
    "# Compute empirical frequency of appearance for 1 star reviews\n",
    "empirical_mean = np.mean( bad_1star )\n",
    "\n",
    "# Compute population mean and standard deviation\n",
    "mu = np.mean(bad_all)\n",
    "sigma = np.std(bad_all)\n",
    "\n",
    "# Get Z score of 1 star reviews\n",
    "z_score = (empirical_mean - mu) /sigma\n",
    "\n",
    "# The actual frequency of appearance \n",
    "print('Frequency of appearance: ', empirical_mean )\n",
    "\n",
    "# The confidence interval for frequency of appearance \n",
    "lower_bound = st.norm.ppf(.025) * sigma + mu \n",
    "upper_bound = st.norm.ppf(.975) * sigma + mu\n",
    "print('Confidence interval for frequency of appearance: ', lower_bound , ' to ', upper_bound )\n",
    "\n",
    "# The statistical significance of frequency of appearance for 1 star reviews \n",
    "print('Statistical significance: ', st.norm.cdf(z_score) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0955755744202\n",
      "0.350330417497\n",
      "count    2.876509e+06\n",
      "mean     9.557557e-02\n",
      "std      3.503305e-01\n",
      "min      0.000000e+00\n",
      "25%      0.000000e+00\n",
      "50%      0.000000e+00\n",
      "75%      0.000000e+00\n",
      "max      1.500000e+01\n",
      "Name: bad, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(mu )\n",
    "print(sigma )\n",
    "print(bad_all.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of appearance:  0.0363429709633\n",
      "Confidence interval for frequency of appearance:  -0.591059426563  to  0.782210575404\n",
      "Statistical significance:  0.4328682765\n"
     ]
    }
   ],
   "source": [
    "# Compute empirical frequency of appearance for 5 star reviews\n",
    "empirical_mean = np.mean( bad_5star )\n",
    "\n",
    "# Compute population mean and standard deviation\n",
    "mu = np.mean(bad_all)\n",
    "sigma = np.std(bad_all)\n",
    "\n",
    "# Get Z score of 5 star reviews\n",
    "z_score = (empirical_mean - mu) /sigma\n",
    "\n",
    "# The actual frequency of appearance \n",
    "print('Frequency of appearance: ', empirical_mean )\n",
    "\n",
    "# The confidence interval for frequency of appearance \n",
    "lower_bound = st.norm.ppf(.025) * sigma + mu\n",
    "upper_bound = st.norm.ppf(.975) * sigma + mu\n",
    "print('Confidence interval for frequency of appearance: ', lower_bound , ' to ', upper_bound )\n",
    "\n",
    "# The statistical significance of frequency of appearance for 5 star reviews \n",
    "print('Statistical significance: ', st.norm.cdf(z_score) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create data sets \n",
    "best_1star = bad_best_df[bad_best_df['stars'] == 1]['best']\n",
    "best_5star = bad_best_df[bad_best_df['stars'] == 5]['best']\n",
    "best_all = bad_best_df['best']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of appearance:  0.0705511949299\n",
      "Confidence interval for frequency of appearance:  -0.736809845008  to  1.12308153753\n",
      "Statistical significance:  0.398064238033\n"
     ]
    }
   ],
   "source": [
    "# Compute empirical frequency of appearance for 1 star reviews\n",
    "empirical_mean = np.mean( best_1star )\n",
    "\n",
    "# Compute population mean and standard deviation\n",
    "mu = np.mean(best_all)\n",
    "sigma = np.std(best_all)\n",
    "\n",
    "# Get Z score of 1 star reviews\n",
    "z_score = (empirical_mean - mu) /sigma\n",
    "\n",
    "# The actual frequency of appearance \n",
    "print('Frequency of appearance: ', empirical_mean )\n",
    "\n",
    "# The confidence interval for frequency of appearance \n",
    "lower_bound = st.norm.ppf(.025) * sigma + mu\n",
    "upper_bound = st.norm.ppf(.975) * sigma + mu\n",
    "print('Confidence interval for frequency of appearance: ', lower_bound , ' to ', upper_bound )\n",
    "\n",
    "# The statistical significance of frequency of appearance for 1 star reviews \n",
    "print('Statistical significance: ', st.norm.cdf(z_score) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of appearance:  0.289232993948\n",
      "Confidence interval for frequency of appearance:  -0.736809845008  to  1.12308153753\n",
      "Statistical significance:  0.580250917587\n"
     ]
    }
   ],
   "source": [
    "# Compute empirical frequency of appearance for 5 star reviews\n",
    "empirical_mean = np.mean( best_5star )\n",
    "\n",
    "# Compute population mean and standard deviation\n",
    "mu = np.mean(best_all)\n",
    "sigma = np.std(best_all)\n",
    "\n",
    "# Get Z score of 5 star reviews\n",
    "z_score = (empirical_mean - mu) /sigma\n",
    "\n",
    "# The actual frequency of appearance \n",
    "print('Frequency of appearance: ', empirical_mean )\n",
    "\n",
    "# The confidence interval for frequency of appearance \n",
    "lower_bound = st.norm.ppf(.025) * sigma + mu\n",
    "upper_bound = st.norm.ppf(.975) * sigma + mu\n",
    "print('Confidence interval for frequency of appearance: ', lower_bound , ' to ', upper_bound )\n",
    "\n",
    "# The statistical significance of frequency of appearance for 5 star reviews \n",
    "print('Statistical significance: ', st.norm.cdf(z_score) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
