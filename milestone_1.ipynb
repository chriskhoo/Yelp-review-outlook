{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dependencies and determine working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/chriskhoo/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Import NLP dictionary\n",
    "import nltk\n",
    "import string # for punctuation\n",
    "import re\n",
    "\n",
    "# Get lemmatizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# import tokenizer\n",
    "from nltk.tokenize import wordpunct_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get current directory\n",
    "dir = os.path.dirname(os.path.abspath('__file__'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load review data \n",
    "# get file path (generalize for different OS) for reviews\n",
    "filename_review = os.path.join(dir, '01_raw_data','review.json')\n",
    "\n",
    "# create a list of reviews\n",
    "with open(filename_review, encoding=\"utf8\", mode='r') as file:\n",
    "    reviews = [json.loads(line) for line in file]\n",
    "\n",
    "# create a pandas data frame from review data \n",
    "reviews_df = pd.DataFrame(reviews)\n",
    "\n",
    "# Load business data \n",
    "# get file path (generalize for different OS) for reviews\n",
    "filename_business = os.path.join(dir, '01_raw_data','business.json')\n",
    "\n",
    "# create a list of reviews\n",
    "with open(filename_business, encoding=\"utf8\", mode='r') as file:\n",
    "    businesses = [json.loads(line) for line in file]\n",
    "\n",
    "# create a pandas data frame from review data \n",
    "businesses_df = pd.DataFrame(businesses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge dataframes and select US Restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert date to a datetime - note stars will be kept as an integer vs category\n",
    "reviews_df['date'] = pd.to_datetime(reviews_df['date'], format='%Y-%m-%d')\n",
    "\n",
    "# Extract restaurants \n",
    "restaurants_df = businesses_df[ businesses_df['categories'].apply(lambda categories: any(pd.Series(categories).str.contains('Restaurants')) if len(categories)>0 else False)]\n",
    "\n",
    "# Restrict restaurants to the USA using a bounding box \n",
    "restaurants_df = restaurants_df[ (restaurants_df['latitude'] >= 24.7433195) & (restaurants_df['latitude'] <= 49.3457868) & (restaurants_df['longitude'] >= -124.7844079) & (restaurants_df['longitude'] <= -66.9513812)]\n",
    "\n",
    "# Merge both data frames\n",
    "joint_df = pd.merge(reviews_df, restaurants_df, on='business_id', suffixes=['_review', '_business'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop all columns other than review text and review stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2876509 entries, 0 to 2876508\n",
      "Data columns (total 2 columns):\n",
      "stars_review    int64\n",
      "text            object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 65.8+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# select only stars_review and text columns \n",
    "joint_df = joint_df.loc[:, ['stars_review', 'text']]\n",
    "print(joint_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process review text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hey', 'you', 'test', 'this', 'sample', 'review', 'with', 'this', 'and', 'this', 'and', 'other', 'punctuation', 'and', 'upper', 'case', 'letter', 'and', 'walk', 'walking', 'walk', 'cat', 'and', 'cactus', 'for', 'lemmatizing']\n"
     ]
    }
   ],
   "source": [
    "# define regex\n",
    "regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "\n",
    "# define pre-processing function\n",
    "def pre_process_review( review_text ):\n",
    "    # Convert all text to lower case, tokenize into list of strings, remove punctuation, and lemmatize\n",
    "    return [lemmatizer.lemmatize(word) for word in wordpunct_tokenize(regex.sub('', review_text.lower()))]\n",
    "\n",
    "# Test pre_process_review function \n",
    "print( pre_process_review(\"Hey you! Test this sample review, with this: and this ...; and other punctuations and UPPER case letters! And walk, walking, walks, cats and cacti for lemmatizing.\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [this, place, is, horrible, we, were, so, exci...\n",
       "1     [for, being, fairly, fast, food, pei, wei, pro...\n",
       "2     [i, decided, to, try, it, out, im, celiac, and...\n",
       "3     [im, not, saying, pei, wei, is, the, best, asi...\n",
       "4     [sometimes, the, food, is, spot, on, and, deli...\n",
       "5     [decent, customer, service, but, the, food, wa...\n",
       "6     [super, clean, restaurant, and, friendly, staf...\n",
       "7     [found, this, the, other, night, it, is, the, ...\n",
       "8     [the, staff, here, is, great, and, theyre, nic...\n",
       "9     [i, had, the, garlic, ginger, broccoli, chicke...\n",
       "10    [this, review, is, based, upon, consistency, o...\n",
       "11    [i, love, this, place, id, recommend, it, to, ...\n",
       "12    [1st, place, is, not, closed, there, wa, an, i...\n",
       "13    [definitely, not, a, fan, coming, from, orange...\n",
       "14    [pretty, good, not, great, definitely, overpri...\n",
       "15    [i, wish, i, could, give, 15, star, nothing, s...\n",
       "16    [disappointed, that, on, yelp, their, hour, sh...\n",
       "17    [1st, visit, had, the, lo, meindelish, 2nd, vi...\n",
       "18    [a, a, vegetarian, it, can, difficult, to, fin...\n",
       "19    [typical, big, business, chinese, place, sligh...\n",
       "Name: processed_review, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply pre processing to review text and store result in a new column\n",
    "joint_df['processed_review'] = joint_df['text'].apply(lambda review_text: pre_process_review( review_text ))\n",
    "\n",
    "# Check output\n",
    "joint_df['processed_review'].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop unprocessed text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del joint_df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2876509 entries, 0 to 2876508\n",
      "Data columns (total 2 columns):\n",
      "stars_review        int64\n",
      "processed_review    object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 65.8+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(joint_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save df into a csv \n",
    "filename_out = os.path.join(dir, '02_processed_data','review_text_stars.csv')\n",
    "joint_df.to_csv(filename_out, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load df from a csv \n",
    "file_path = os.path.join(dir, '02_processed_data','review_text_stars.csv')\n",
    "joint_df2 = pd.read_csv(file_path, index_col = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved df shape: (2876509, 2)\n",
      "Loaded df shape: (2876509, 2)\n",
      "-------------\n",
      "Saved df info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2876509 entries, 0 to 2876508\n",
      "Data columns (total 2 columns):\n",
      "stars_review        int64\n",
      "processed_review    object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 65.8+ MB\n",
      "None\n",
      "-------------\n",
      "Loaded df info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2876509 entries, 0 to 2876508\n",
      "Data columns (total 2 columns):\n",
      "stars_review        int64\n",
      "processed_review    object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 43.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# run checks to see the data frames are similar\n",
    "print( 'Saved df shape:', str(joint_df.shape) )\n",
    "print( 'Loaded df shape:', str(joint_df2.shape) )\n",
    "print( '-------------')\n",
    "print( 'Saved df info:')\n",
    "print( joint_df.info() )\n",
    "print( '-------------')\n",
    "print( 'Loaded df info:')\n",
    "print( joint_df2.info() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
